{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"urMLtGFqfTYG","executionInfo":{"status":"ok","timestamp":1669878144794,"user_tz":-540,"elapsed":40863,"user":{"displayName":"","userId":""}},"outputId":"7dbba836-4d18-49c1-d094-87f513c6124d","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'notebook-bench'...\n","remote: Enumerating objects: 53, done.\u001b[K\n","remote: Counting objects: 100% (53/53), done.\u001b[K\n","remote: Compressing objects: 100% (37/37), done.\u001b[K\n","remote: Total 53 (delta 9), reused 48 (delta 7), pack-reused 0\u001b[K\n","Unpacking objects: 100% (53/53), done.\n","/content/notebook-bench\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers[torch]==4.24.0\n","  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n","\u001b[K     |████████████████████████████████| 5.5 MB 13.5 MB/s \n","\u001b[?25hCollecting fugashi==1.2.0\n","  Downloading fugashi-1.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615 kB)\n","\u001b[K     |████████████████████████████████| 615 kB 38.1 MB/s \n","\u001b[?25hCollecting ipadic==1.0.0\n","  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n","\u001b[K     |████████████████████████████████| 13.4 MB 33.8 MB/s \n","\u001b[?25hCollecting pandas==1.5.2\n","  Downloading pandas-1.5.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n","\u001b[K     |████████████████████████████████| 12.2 MB 65.5 MB/s \n","\u001b[?25hCollecting scikit-learn==1.1.3\n","  Downloading scikit_learn-1.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n","\u001b[K     |████████████████████████████████| 31.2 MB 1.5 MB/s \n","\u001b[?25hCollecting datasets==2.7.1\n","  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n","\u001b[K     |████████████████████████████████| 451 kB 67.4 MB/s \n","\u001b[?25hCollecting sentencepiece==0.1.97\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 57.0 MB/s \n","\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (3.6.4)\n","Collecting pre-commit\n","  Downloading pre_commit-2.20.0-py2.py3-none-any.whl (199 kB)\n","\u001b[K     |████████████████████████████████| 199 kB 75.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.8/dist-packages (from pandas==1.5.2->-r requirements.txt (line 4)) (1.21.6)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.5.2->-r requirements.txt (line 4)) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.5.2->-r requirements.txt (line 4)) (2.8.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.1.3->-r requirements.txt (line 5)) (3.1.0)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.1.3->-r requirements.txt (line 5)) (1.7.3)\n","Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.1.3->-r requirements.txt (line 5)) (1.2.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 6)) (21.3)\n","Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 6)) (0.3.6)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 6)) (3.8.3)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 6)) (9.0.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 6)) (2022.11.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 6)) (6.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 6)) (2.23.0)\n","Collecting huggingface-hub<1.0.0,>=0.2.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 74.3 MB/s \n","\u001b[?25hCollecting multiprocess\n","  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 56.3 MB/s \n","\u001b[?25hCollecting xxhash\n","  Downloading xxhash-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 55.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets==2.7.1->-r requirements.txt (line 6)) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers[torch]==4.24.0->-r requirements.txt (line 1)) (3.8.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 58.4 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]==4.24.0->-r requirements.txt (line 1)) (2022.6.2)\n","Requirement already satisfied: torch!=1.12.0,>=1.7 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]==4.24.0->-r requirements.txt (line 1)) (1.12.1+cu113)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 6)) (2.1.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 6)) (22.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 6)) (1.8.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 6)) (1.3.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 6)) (1.3.3)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 6)) (4.0.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.7.1->-r requirements.txt (line 6)) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.7.1->-r requirements.txt (line 6)) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets==2.7.1->-r requirements.txt (line 6)) (3.0.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.2->-r requirements.txt (line 4)) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==2.7.1->-r requirements.txt (line 6)) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==2.7.1->-r requirements.txt (line 6)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==2.7.1->-r requirements.txt (line 6)) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==2.7.1->-r requirements.txt (line 6)) (3.0.4)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 76.3 MB/s \n","\u001b[?25hRequirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.8/dist-packages (from pytest->-r requirements.txt (line 8)) (0.7.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from pytest->-r requirements.txt (line 8)) (57.4.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytest->-r requirements.txt (line 8)) (9.0.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.8/dist-packages (from pytest->-r requirements.txt (line 8)) (1.4.1)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from pytest->-r requirements.txt (line 8)) (1.11.0)\n","Collecting cfgv>=2.0.0\n","  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n","Collecting nodeenv>=0.11.1\n","  Downloading nodeenv-1.7.0-py2.py3-none-any.whl (21 kB)\n","Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from pre-commit->-r requirements.txt (line 9)) (0.10.2)\n","Collecting identify>=1.0.0\n","  Downloading identify-2.5.9-py2.py3-none-any.whl (98 kB)\n","\u001b[K     |████████████████████████████████| 98 kB 9.6 MB/s \n","\u001b[?25hCollecting virtualenv>=20.0.8\n","  Downloading virtualenv-20.17.0-py3-none-any.whl (8.8 MB)\n","\u001b[K     |████████████████████████████████| 8.8 MB 58.2 MB/s \n","\u001b[?25hCollecting distlib<1,>=0.3.6\n","  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n","\u001b[K     |████████████████████████████████| 468 kB 75.5 MB/s \n","\u001b[?25hCollecting platformdirs<3,>=2.4\n","  Downloading platformdirs-2.5.4-py3-none-any.whl (14 kB)\n","Building wheels for collected packages: ipadic\n","  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556723 sha256=14d6e28d4576a2af539ca63375dec3cc926e1a00ea494fd4761438c34908fddb\n","  Stored in directory: /root/.cache/pip/wheels/45/b7/f5/a21e68db846eedcd00d69e37d60bab3f68eb20b1d99cdff652\n","Successfully built ipadic\n","Installing collected packages: urllib3, tokenizers, platformdirs, huggingface-hub, distlib, xxhash, virtualenv, transformers, responses, pandas, nodeenv, multiprocess, identify, cfgv, sentencepiece, scikit-learn, pre-commit, ipadic, fugashi, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.3.5\n","    Uninstalling pandas-1.3.5:\n","      Successfully uninstalled pandas-1.3.5\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.0.2\n","    Uninstalling scikit-learn-1.0.2:\n","      Successfully uninstalled scikit-learn-1.0.2\n","Successfully installed cfgv-3.3.1 datasets-2.7.1 distlib-0.3.6 fugashi-1.2.0 huggingface-hub-0.11.1 identify-2.5.9 ipadic-1.0.0 multiprocess-0.70.14 nodeenv-1.7.0 pandas-1.5.2 platformdirs-2.5.4 pre-commit-2.20.0 responses-0.18.0 scikit-learn-1.1.3 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.24.0 urllib3-1.25.11 virtualenv-20.17.0 xxhash-3.1.0\n"]}],"source":["!git clone https://github.com/icoxfog417/notebook-bench.git\n","%cd notebook-bench/\n","%pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"Jwwae-2mfTYL"},"source":["### For Studio Lab\n","\n","Create the environment before runnning the notebok"]},{"cell_type":"markdown","metadata":{"id":"wECmTFM7fTYO"},"source":["## Calculation"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"wnHdzuurfTYQ","executionInfo":{"status":"ok","timestamp":1669878146226,"user_tz":-540,"elapsed":1450,"user":{"displayName":"","userId":""}},"outputId":"d0464d3a-6194-448a-91ec-e8547717aa57","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Dec  1 07:02:24 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P0    25W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"qk6ZIzpwfTYR","executionInfo":{"status":"ok","timestamp":1669878146227,"user_tz":-540,"elapsed":9,"user":{"displayName":"","userId":""}},"outputId":"4309d102-b231-4cd3-8be4-2907e653a0f7","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/notebook-bench\n"]}],"source":["import time\n","import os\n","from pathlib import Path\n","\n","\n","if Path.cwd().name == \"notebooks\":\n","    os.chdir(Path.cwd().parent)\n","\n","print(Path.cwd())"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"qjHIoSE8fTYS","executionInfo":{"status":"ok","timestamp":1669882313237,"user_tz":-540,"elapsed":4167016,"user":{"displayName":"","userId":""}},"outputId":"ae2689a0-a195-4e5d-c28a-26e52e1e9253","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading: 100% 479/479 [00:00<00:00, 350kB/s]\n","Downloading: 100% 445M/445M [00:05<00:00, 86.4MB/s]\n","Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Downloading: 100% 110/110 [00:00<00:00, 86.9kB/s]\n","Downloading: 100% 258k/258k [00:00<00:00, 748kB/s]\n","Downloading builder script: 100% 7.16k/7.16k [00:00<00:00, 5.51MB/s]\n","Downloading metadata: 100% 37.4k/37.4k [00:00<00:00, 432kB/s]\n","Downloading readme: 100% 13.4k/13.4k [00:00<00:00, 9.49MB/s]\n","Downloading and preparing dataset amazon_reviews_multi/ja to /root/.cache/huggingface/datasets/amazon_reviews_multi/ja/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609...\n","Downloading data files:   0% 0/1 [00:00<?, ?it/s]\n","Downloading data:   0% 0.00/169M [00:00<?, ?B/s]\u001b[A\n","Downloading data:   0% 18.4k/169M [00:00<22:55, 123kB/s]\u001b[A\n","Downloading data:   0% 52.2k/169M [00:00<16:42, 169kB/s]\u001b[A\n","Downloading data:   0% 122k/169M [00:00<09:29, 297kB/s] \u001b[A\n","Downloading data:   0% 279k/169M [00:00<04:57, 568kB/s]\u001b[A\n","Downloading data:   0% 592k/169M [00:00<02:37, 1.07MB/s]\u001b[A\n","Downloading data:   1% 1.20M/169M [00:00<01:24, 2.00MB/s]\u001b[A\n","Downloading data:   1% 2.43M/169M [00:01<00:43, 3.84MB/s]\u001b[A\n","Downloading data:   3% 4.90M/169M [00:01<00:21, 7.52MB/s]\u001b[A\n","Downloading data:   4% 6.77M/169M [00:01<00:18, 8.79MB/s]\u001b[A\n","Downloading data:   5% 9.11M/169M [00:01<00:15, 10.6MB/s]\u001b[A\n","Downloading data:   7% 11.7M/169M [00:01<00:12, 12.3MB/s]\u001b[A\n","Downloading data:   8% 14.2M/169M [00:01<00:11, 13.2MB/s]\u001b[A\n","Downloading data:  10% 16.6M/169M [00:02<00:11, 13.8MB/s]\u001b[A\n","Downloading data:  11% 19.1M/169M [00:02<00:10, 14.3MB/s]\u001b[A\n","Downloading data:  13% 21.6M/169M [00:02<00:10, 14.6MB/s]\u001b[A\n","Downloading data:  14% 24.1M/169M [00:02<00:09, 14.9MB/s]\u001b[A\n","Downloading data:  16% 26.4M/169M [00:02<00:09, 14.8MB/s]\u001b[A\n","Downloading data:  17% 29.0M/169M [00:02<00:09, 15.1MB/s]\u001b[A\n","Downloading data:  19% 31.5M/169M [00:03<00:09, 15.2MB/s]\u001b[A\n","Downloading data:  20% 33.9M/169M [00:03<00:08, 15.2MB/s]\u001b[A\n","Downloading data:  22% 36.5M/169M [00:03<00:08, 15.4MB/s]\u001b[A\n","Downloading data:  23% 38.9M/169M [00:03<00:08, 15.3MB/s]\u001b[A\n","Downloading data:  24% 41.3M/169M [00:03<00:08, 15.2MB/s]\u001b[A\n","Downloading data:  26% 43.9M/169M [00:03<00:08, 15.4MB/s]\u001b[A\n","Downloading data:  27% 46.3M/169M [00:04<00:08, 15.3MB/s]\u001b[A\n","Downloading data:  29% 48.8M/169M [00:04<00:07, 15.4MB/s]\u001b[A\n","Downloading data:  30% 51.4M/169M [00:04<00:07, 15.6MB/s]\u001b[A\n","Downloading data:  32% 53.8M/169M [00:04<00:07, 15.4MB/s]\u001b[A\n","Downloading data:  33% 56.4M/169M [00:04<00:07, 15.6MB/s]\u001b[A\n","Downloading data:  35% 58.9M/169M [00:04<00:07, 15.5MB/s]\u001b[A\n","Downloading data:  36% 61.5M/169M [00:04<00:06, 15.7MB/s]\u001b[A\n","Downloading data:  38% 64.0M/169M [00:05<00:06, 15.7MB/s]\u001b[A\n","Downloading data:  39% 66.5M/169M [00:05<00:06, 15.7MB/s]\u001b[A\n","Downloading data:  41% 69.1M/169M [00:05<00:06, 15.7MB/s]\u001b[A\n","Downloading data:  42% 71.6M/169M [00:05<00:06, 15.6MB/s]\u001b[A\n","Downloading data:  44% 73.9M/169M [00:05<00:06, 15.2MB/s]\u001b[A\n","Downloading data:  45% 76.7M/169M [00:05<00:05, 15.9MB/s]\u001b[A\n","Downloading data:  47% 79.0M/169M [00:06<00:05, 15.5MB/s]\u001b[A\n","Downloading data:  48% 81.6M/169M [00:06<00:05, 15.7MB/s]\u001b[A\n","Downloading data:  50% 83.9M/169M [00:06<00:05, 15.2MB/s]\u001b[A\n","Downloading data:  51% 86.5M/169M [00:06<00:05, 15.6MB/s]\u001b[A\n","Downloading data:  52% 88.9M/169M [00:06<00:05, 15.3MB/s]\u001b[A\n","Downloading data:  54% 91.5M/169M [00:06<00:04, 15.6MB/s]\u001b[A\n","Downloading data:  55% 94.0M/169M [00:07<00:04, 15.5MB/s]\u001b[A\n","Downloading data:  57% 96.6M/169M [00:07<00:04, 15.7MB/s]\u001b[A\n","Downloading data:  58% 99.1M/169M [00:07<00:04, 15.6MB/s]\u001b[A\n","Downloading data:  60% 102M/169M [00:07<00:04, 15.7MB/s] \u001b[A\n","Downloading data:  62% 104M/169M [00:07<00:04, 15.8MB/s]\u001b[A\n","Downloading data:  63% 107M/169M [00:07<00:03, 15.9MB/s]\u001b[A\n","Downloading data:  65% 109M/169M [00:08<00:03, 15.8MB/s]\u001b[A\n","Downloading data:  66% 112M/169M [00:08<00:03, 15.4MB/s]\u001b[A\n","Downloading data:  68% 114M/169M [00:08<00:03, 15.9MB/s]\u001b[A\n","Downloading data:  69% 117M/169M [00:08<00:03, 15.4MB/s]\u001b[A\n","Downloading data:  70% 119M/169M [00:08<00:03, 15.1MB/s]\u001b[A\n","Downloading data:  72% 122M/169M [00:08<00:03, 15.6MB/s]\u001b[A\n","Downloading data:  73% 124M/169M [00:09<00:02, 15.7MB/s]\u001b[A\n","Downloading data:  75% 127M/169M [00:09<00:02, 15.7MB/s]\u001b[A\n","Downloading data:  76% 130M/169M [00:09<00:02, 16.0MB/s]\u001b[A\n","Downloading data:  78% 132M/169M [00:09<00:02, 16.0MB/s]\u001b[A\n","Downloading data:  80% 135M/169M [00:09<00:02, 16.1MB/s]\u001b[A\n","Downloading data:  81% 137M/169M [00:09<00:01, 16.1MB/s]\u001b[A\n","Downloading data:  83% 140M/169M [00:09<00:01, 16.3MB/s]\u001b[A\n","Downloading data:  84% 142M/169M [00:10<00:01, 16.0MB/s]\u001b[A\n","Downloading data:  86% 145M/169M [00:10<00:01, 16.2MB/s]\u001b[A\n","Downloading data:  87% 148M/169M [00:10<00:01, 16.1MB/s]\u001b[A\n","Downloading data:  89% 150M/169M [00:10<00:01, 16.0MB/s]\u001b[A\n","Downloading data:  90% 153M/169M [00:10<00:01, 16.0MB/s]\u001b[A\n","Downloading data:  92% 155M/169M [00:10<00:00, 16.0MB/s]\u001b[A\n","Downloading data:  93% 158M/169M [00:11<00:00, 16.1MB/s]\u001b[A\n","Downloading data:  95% 161M/169M [00:11<00:00, 16.0MB/s]\u001b[A\n","Downloading data:  96% 163M/169M [00:11<00:00, 15.9MB/s]\u001b[A\n","Downloading data:  98% 166M/169M [00:11<00:00, 16.2MB/s]\u001b[A\n","Downloading data: 100% 169M/169M [00:11<00:00, 14.4MB/s]\n","Downloading data files: 100% 1/1 [00:13<00:00, 13.25s/it]\n","Extracting data files: 100% 1/1 [00:00<00:00, 1123.88it/s]\n","Downloading data files:   0% 0/1 [00:00<?, ?it/s]\n","Downloading data:   0% 0.00/4.19M [00:00<?, ?B/s]\u001b[A\n","Downloading data:   0% 17.4k/4.19M [00:00<00:39, 107kB/s]\u001b[A\n","Downloading data:   1% 52.2k/4.19M [00:00<00:24, 169kB/s]\u001b[A\n","Downloading data:   3% 122k/4.19M [00:00<00:14, 285kB/s] \u001b[A\n","Downloading data:   6% 261k/4.19M [00:00<00:07, 533kB/s]\u001b[A\n","Downloading data:  13% 557k/4.19M [00:00<00:03, 1.01MB/s]\u001b[A\n","Downloading data:  27% 1.15M/4.19M [00:00<00:01, 1.91MB/s]\u001b[A\n","Downloading data: 100% 4.19M/4.19M [00:01<00:00, 3.59MB/s]\n","Downloading data files: 100% 1/1 [00:02<00:00,  2.70s/it]\n","Extracting data files: 100% 1/1 [00:00<00:00, 1191.56it/s]\n","Downloading data files:   0% 0/1 [00:00<?, ?it/s]\n","Downloading data:   0% 0.00/4.21M [00:00<?, ?B/s]\u001b[A\n","Downloading data:   0% 17.4k/4.21M [00:00<00:38, 109kB/s]\u001b[A\n","Downloading data:   1% 51.2k/4.21M [00:00<00:24, 169kB/s]\u001b[A\n","Downloading data:   3% 121k/4.21M [00:00<00:14, 291kB/s] \u001b[A\n","Downloading data:   7% 278k/4.21M [00:00<00:06, 579kB/s]\u001b[A\n","Downloading data:  14% 573k/4.21M [00:00<00:03, 1.05MB/s]\u001b[A\n","Downloading data:  28% 1.18M/4.21M [00:00<00:01, 2.00MB/s]\u001b[A\n","Downloading data: 100% 4.21M/4.21M [00:01<00:00, 3.70MB/s]\n","Downloading data files: 100% 1/1 [00:02<00:00,  2.61s/it]\n","Extracting data files: 100% 1/1 [00:00<00:00, 1213.63it/s]\n","Dataset amazon_reviews_multi downloaded and prepared to /root/.cache/huggingface/datasets/amazon_reviews_multi/ja/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609. Subsequent calls will reuse this data.\n","100% 5/5 [00:00<00:00, 92.10ba/s]\n","100% 5/5 [00:00<00:00, 70.54ba/s]\n","100% 2/2 [00:00<00:00,  4.80ba/s]\n","100% 2/2 [00:01<00:00,  1.84ba/s]\n","100% 1/1 [00:00<00:00, 10.18ba/s]\n","100% 1/1 [00:00<00:00,  3.63ba/s]\n","Train data statistics: {'total': 1600, 'positive': 809, 'negative': 791}\n","Test data statistics: {'total': 400, 'positive': 191, 'negative': 209}\n","The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: review_body, review_id, stars, language, reviewer_id, product_id, product_category, review_title. If review_body, review_id, stars, language, reviewer_id, product_id, product_category, review_title are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1600\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 600\n","  Number of trainable parameters = 110618882\n"," 33% 200/600 [02:20<04:48,  1.39it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: review_body, review_id, stars, language, reviewer_id, product_id, product_category, review_title. If review_body, review_id, stars, language, reviewer_id, product_id, product_category, review_title are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 8\n","\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:06,  8.00it/s]\u001b[A\n","  6% 3/50 [00:00<00:08,  5.54it/s]\u001b[A\n","  8% 4/50 [00:00<00:09,  4.76it/s]\u001b[A\n"," 10% 5/50 [00:01<00:10,  4.46it/s]\u001b[A\n"," 12% 6/50 [00:01<00:10,  4.25it/s]\u001b[A\n"," 14% 7/50 [00:01<00:10,  4.15it/s]\u001b[A\n"," 16% 8/50 [00:01<00:10,  4.07it/s]\u001b[A\n"," 18% 9/50 [00:02<00:10,  4.00it/s]\u001b[A\n"," 20% 10/50 [00:02<00:09,  4.01it/s]\u001b[A\n"," 22% 11/50 [00:02<00:09,  3.96it/s]\u001b[A\n"," 24% 12/50 [00:02<00:09,  3.95it/s]\u001b[A\n"," 26% 13/50 [00:03<00:09,  3.94it/s]\u001b[A\n"," 28% 14/50 [00:03<00:09,  3.92it/s]\u001b[A\n"," 30% 15/50 [00:03<00:08,  3.92it/s]\u001b[A\n"," 32% 16/50 [00:03<00:08,  3.93it/s]\u001b[A\n"," 34% 17/50 [00:04<00:08,  3.89it/s]\u001b[A\n"," 36% 18/50 [00:04<00:08,  3.88it/s]\u001b[A\n"," 38% 19/50 [00:04<00:07,  3.92it/s]\u001b[A\n"," 40% 20/50 [00:04<00:07,  3.90it/s]\u001b[A\n"," 42% 21/50 [00:05<00:07,  3.88it/s]\u001b[A\n"," 44% 22/50 [00:05<00:07,  3.87it/s]\u001b[A\n"," 46% 23/50 [00:05<00:06,  3.91it/s]\u001b[A\n"," 48% 24/50 [00:05<00:06,  3.89it/s]\u001b[A\n"," 50% 25/50 [00:06<00:06,  3.89it/s]\u001b[A\n"," 52% 26/50 [00:06<00:06,  3.90it/s]\u001b[A\n"," 54% 27/50 [00:06<00:05,  3.90it/s]\u001b[A\n"," 56% 28/50 [00:06<00:05,  3.91it/s]\u001b[A\n"," 58% 29/50 [00:07<00:05,  3.90it/s]\u001b[A\n"," 60% 30/50 [00:07<00:05,  3.88it/s]\u001b[A\n"," 62% 31/50 [00:07<00:04,  3.88it/s]\u001b[A\n"," 64% 32/50 [00:07<00:04,  3.92it/s]\u001b[A\n"," 66% 33/50 [00:08<00:04,  3.88it/s]\u001b[A\n"," 68% 34/50 [00:08<00:04,  3.86it/s]\u001b[A\n"," 70% 35/50 [00:08<00:03,  3.86it/s]\u001b[A\n"," 72% 36/50 [00:08<00:03,  3.90it/s]\u001b[A\n"," 74% 37/50 [00:09<00:03,  3.87it/s]\u001b[A\n"," 76% 38/50 [00:09<00:03,  3.86it/s]\u001b[A\n"," 78% 39/50 [00:09<00:02,  3.85it/s]\u001b[A\n"," 80% 40/50 [00:10<00:02,  3.86it/s]\u001b[A\n"," 82% 41/50 [00:10<00:02,  3.87it/s]\u001b[A\n"," 84% 42/50 [00:10<00:02,  3.87it/s]\u001b[A\n"," 86% 43/50 [00:10<00:01,  3.85it/s]\u001b[A\n"," 88% 44/50 [00:11<00:01,  3.85it/s]\u001b[A\n"," 90% 45/50 [00:11<00:01,  3.83it/s]\u001b[A\n"," 92% 46/50 [00:11<00:01,  3.82it/s]\u001b[A\n"," 94% 47/50 [00:11<00:00,  3.84it/s]\u001b[A\n"," 96% 48/50 [00:12<00:00,  3.86it/s]\u001b[A\n"," 98% 49/50 [00:12<00:00,  3.85it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.32671302556991577, 'eval_accuracy': 0.905, 'eval_precision': 0.8963730569948186, 'eval_recall': 0.9057591623036649, 'eval_f1': 0.9010416666666666, 'eval_runtime': 12.8847, 'eval_samples_per_second': 31.045, 'eval_steps_per_second': 3.881, 'epoch': 1.0}\n"," 33% 200/600 [02:33<04:48,  1.39it/s]\n","100% 50/50 [00:12<00:00,  3.84it/s]\u001b[A\n","                                   \u001b[ASaving model checkpoint to output/checkpoint-200\n","Configuration saved in output/checkpoint-200/config.json\n","Model weights saved in output/checkpoint-200/pytorch_model.bin\n"," 67% 400/600 [05:04<02:26,  1.36it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: review_body, review_id, stars, language, reviewer_id, product_id, product_category, review_title. If review_body, review_id, stars, language, reviewer_id, product_id, product_category, review_title are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 8\n","\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:06,  7.49it/s]\u001b[A\n","  6% 3/50 [00:00<00:08,  5.27it/s]\u001b[A\n","  8% 4/50 [00:00<00:10,  4.54it/s]\u001b[A\n"," 10% 5/50 [00:01<00:10,  4.23it/s]\u001b[A\n"," 12% 6/50 [00:01<00:10,  4.04it/s]\u001b[A\n"," 14% 7/50 [00:01<00:10,  3.93it/s]\u001b[A\n"," 16% 8/50 [00:01<00:10,  3.87it/s]\u001b[A\n"," 18% 9/50 [00:02<00:10,  3.83it/s]\u001b[A\n"," 20% 10/50 [00:02<00:10,  3.80it/s]\u001b[A\n"," 22% 11/50 [00:02<00:10,  3.78it/s]\u001b[A\n"," 24% 12/50 [00:02<00:10,  3.78it/s]\u001b[A\n"," 26% 13/50 [00:03<00:09,  3.76it/s]\u001b[A\n"," 28% 14/50 [00:03<00:09,  3.74it/s]\u001b[A\n"," 30% 15/50 [00:03<00:09,  3.75it/s]\u001b[A\n"," 32% 16/50 [00:04<00:09,  3.76it/s]\u001b[A\n"," 34% 17/50 [00:04<00:08,  3.76it/s]\u001b[A\n"," 36% 18/50 [00:04<00:08,  3.75it/s]\u001b[A\n"," 38% 19/50 [00:04<00:08,  3.74it/s]\u001b[A\n"," 40% 20/50 [00:05<00:08,  3.73it/s]\u001b[A\n"," 42% 21/50 [00:05<00:07,  3.74it/s]\u001b[A\n"," 44% 22/50 [00:05<00:07,  3.75it/s]\u001b[A\n"," 46% 23/50 [00:05<00:07,  3.75it/s]\u001b[A\n"," 48% 24/50 [00:06<00:06,  3.75it/s]\u001b[A\n"," 50% 25/50 [00:06<00:06,  3.73it/s]\u001b[A\n"," 52% 26/50 [00:06<00:06,  3.74it/s]\u001b[A\n"," 54% 27/50 [00:06<00:06,  3.75it/s]\u001b[A\n"," 56% 28/50 [00:07<00:05,  3.76it/s]\u001b[A\n"," 58% 29/50 [00:07<00:05,  3.76it/s]\u001b[A\n"," 60% 30/50 [00:07<00:05,  3.75it/s]\u001b[A\n"," 62% 31/50 [00:08<00:05,  3.75it/s]\u001b[A\n"," 64% 32/50 [00:08<00:04,  3.73it/s]\u001b[A\n"," 66% 33/50 [00:08<00:04,  3.74it/s]\u001b[A\n"," 68% 34/50 [00:08<00:04,  3.74it/s]\u001b[A\n"," 70% 35/50 [00:09<00:03,  3.75it/s]\u001b[A\n"," 72% 36/50 [00:09<00:03,  3.72it/s]\u001b[A\n"," 74% 37/50 [00:09<00:03,  3.74it/s]\u001b[A\n"," 76% 38/50 [00:09<00:03,  3.75it/s]\u001b[A\n"," 78% 39/50 [00:10<00:02,  3.76it/s]\u001b[A\n"," 80% 40/50 [00:10<00:02,  3.75it/s]\u001b[A\n"," 82% 41/50 [00:10<00:02,  3.74it/s]\u001b[A\n"," 84% 42/50 [00:10<00:02,  3.73it/s]\u001b[A\n"," 86% 43/50 [00:11<00:01,  3.74it/s]\u001b[A\n"," 88% 44/50 [00:11<00:01,  3.74it/s]\u001b[A\n"," 90% 45/50 [00:11<00:01,  3.73it/s]\u001b[A\n"," 92% 46/50 [00:12<00:01,  3.75it/s]\u001b[A\n"," 94% 47/50 [00:12<00:00,  3.75it/s]\u001b[A\n"," 96% 48/50 [00:12<00:00,  3.73it/s]\u001b[A\n"," 98% 49/50 [00:12<00:00,  3.74it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.3533758521080017, 'eval_accuracy': 0.91, 'eval_precision': 0.9144385026737968, 'eval_recall': 0.8952879581151832, 'eval_f1': 0.9047619047619048, 'eval_runtime': 13.3694, 'eval_samples_per_second': 29.919, 'eval_steps_per_second': 3.74, 'epoch': 2.0}\n"," 67% 400/600 [05:18<02:26,  1.36it/s]\n","100% 50/50 [00:13<00:00,  3.75it/s]\u001b[A\n","                                   \u001b[ASaving model checkpoint to output/checkpoint-400\n","Configuration saved in output/checkpoint-400/config.json\n","Model weights saved in output/checkpoint-400/pytorch_model.bin\n","{'loss': 0.2716, 'learning_rate': 8.333333333333334e-06, 'epoch': 2.5}\n","100% 600/600 [07:49<00:00,  1.37it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: review_body, review_id, stars, language, reviewer_id, product_id, product_category, review_title. If review_body, review_id, stars, language, reviewer_id, product_id, product_category, review_title are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 8\n","\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:06,  7.48it/s]\u001b[A\n","  6% 3/50 [00:00<00:08,  5.31it/s]\u001b[A\n","  8% 4/50 [00:00<00:09,  4.64it/s]\u001b[A\n"," 10% 5/50 [00:01<00:10,  4.32it/s]\u001b[A\n"," 12% 6/50 [00:01<00:10,  4.11it/s]\u001b[A\n"," 14% 7/50 [00:01<00:10,  3.98it/s]\u001b[A\n"," 16% 8/50 [00:01<00:10,  3.94it/s]\u001b[A\n"," 18% 9/50 [00:02<00:10,  3.90it/s]\u001b[A\n"," 20% 10/50 [00:02<00:10,  3.86it/s]\u001b[A\n"," 22% 11/50 [00:02<00:10,  3.83it/s]\u001b[A\n"," 24% 12/50 [00:02<00:09,  3.83it/s]\u001b[A\n"," 26% 13/50 [00:03<00:09,  3.82it/s]\u001b[A\n"," 28% 14/50 [00:03<00:09,  3.81it/s]\u001b[A\n"," 30% 15/50 [00:03<00:09,  3.80it/s]\u001b[A\n"," 32% 16/50 [00:03<00:08,  3.81it/s]\u001b[A\n"," 34% 17/50 [00:04<00:08,  3.80it/s]\u001b[A\n"," 36% 18/50 [00:04<00:08,  3.79it/s]\u001b[A\n"," 38% 19/50 [00:04<00:08,  3.79it/s]\u001b[A\n"," 40% 20/50 [00:05<00:07,  3.80it/s]\u001b[A\n"," 42% 21/50 [00:05<00:07,  3.78it/s]\u001b[A\n"," 44% 22/50 [00:05<00:07,  3.78it/s]\u001b[A\n"," 46% 23/50 [00:05<00:07,  3.79it/s]\u001b[A\n"," 48% 24/50 [00:06<00:06,  3.80it/s]\u001b[A\n"," 50% 25/50 [00:06<00:06,  3.78it/s]\u001b[A\n"," 52% 26/50 [00:06<00:06,  3.78it/s]\u001b[A\n"," 54% 27/50 [00:06<00:06,  3.80it/s]\u001b[A\n"," 56% 28/50 [00:07<00:05,  3.80it/s]\u001b[A\n"," 58% 29/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 60% 30/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 62% 31/50 [00:07<00:04,  3.80it/s]\u001b[A\n"," 64% 32/50 [00:08<00:04,  3.80it/s]\u001b[A\n"," 66% 33/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 68% 34/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 70% 35/50 [00:08<00:03,  3.80it/s]\u001b[A\n"," 72% 36/50 [00:09<00:03,  3.80it/s]\u001b[A\n"," 74% 37/50 [00:09<00:03,  3.79it/s]\u001b[A\n"," 76% 38/50 [00:09<00:03,  3.80it/s]\u001b[A\n"," 78% 39/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 80% 40/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 82% 41/50 [00:10<00:02,  3.78it/s]\u001b[A\n"," 84% 42/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 86% 43/50 [00:11<00:01,  3.80it/s]\u001b[A\n"," 88% 44/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 90% 45/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 92% 46/50 [00:11<00:01,  3.80it/s]\u001b[A\n"," 94% 47/50 [00:12<00:00,  3.80it/s]\u001b[A\n"," 96% 48/50 [00:12<00:00,  3.78it/s]\u001b[A\n"," 98% 49/50 [00:12<00:00,  3.79it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.3716597855091095, 'eval_accuracy': 0.9275, 'eval_precision': 0.9354838709677419, 'eval_recall': 0.9109947643979057, 'eval_f1': 0.9230769230769231, 'eval_runtime': 13.195, 'eval_samples_per_second': 30.314, 'eval_steps_per_second': 3.789, 'epoch': 3.0}\n","100% 600/600 [08:02<00:00,  1.37it/s]\n","100% 50/50 [00:12<00:00,  3.80it/s]\u001b[A\n","                                   \u001b[ASaving model checkpoint to output/checkpoint-600\n","Configuration saved in output/checkpoint-600/config.json\n","Model weights saved in output/checkpoint-600/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from output/checkpoint-200 (score: 0.32671302556991577).\n","{'train_runtime': 488.3217, 'train_samples_per_second': 9.83, 'train_steps_per_second': 1.229, 'train_loss': 0.23516059160232544, 'epoch': 3.0}\n","100% 600/600 [08:08<00:00,  1.23it/s]\n","Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","WARNING:datasets.builder:Found cached dataset amazon_reviews_multi (/root/.cache/huggingface/datasets/amazon_reviews_multi/ja/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/amazon_reviews_multi/ja/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-83f8d432a1e3b464.arrow\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/amazon_reviews_multi/ja/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-725ca478270fd589.arrow\n","100% 2/2 [00:00<00:00,  3.63ba/s]\n","100% 2/2 [00:01<00:00,  1.72ba/s]\n","100% 1/1 [00:00<00:00,  9.08ba/s]\n","100% 1/1 [00:00<00:00,  3.62ba/s]\n","Train data statistics: {'total': 1600, 'positive': 800, 'negative': 800}\n","Test data statistics: {'total': 400, 'positive': 200, 'negative': 200}\n","The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: language, review_title, stars, product_category, product_id, review_body, reviewer_id, review_id. If language, review_title, stars, product_category, product_id, review_body, reviewer_id, review_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1600\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 600\n","  Number of trainable parameters = 110618882\n"," 33% 200/600 [02:27<04:52,  1.37it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: language, review_title, stars, product_category, product_id, review_body, reviewer_id, review_id. If language, review_title, stars, product_category, product_id, review_body, reviewer_id, review_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 8\n","\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:06,  7.47it/s]\u001b[A\n","  6% 3/50 [00:00<00:08,  5.28it/s]\u001b[A\n","  8% 4/50 [00:00<00:10,  4.57it/s]\u001b[A\n"," 10% 5/50 [00:01<00:10,  4.32it/s]\u001b[A\n"," 12% 6/50 [00:01<00:10,  4.09it/s]\u001b[A\n"," 14% 7/50 [00:01<00:10,  3.98it/s]\u001b[A\n"," 16% 8/50 [00:01<00:10,  3.94it/s]\u001b[A\n"," 18% 9/50 [00:02<00:10,  3.91it/s]\u001b[A\n"," 20% 10/50 [00:02<00:10,  3.85it/s]\u001b[A\n"," 22% 11/50 [00:02<00:10,  3.83it/s]\u001b[A\n"," 24% 12/50 [00:02<00:09,  3.83it/s]\u001b[A\n"," 26% 13/50 [00:03<00:09,  3.83it/s]\u001b[A\n"," 28% 14/50 [00:03<00:09,  3.80it/s]\u001b[A\n"," 30% 15/50 [00:03<00:09,  3.78it/s]\u001b[A\n"," 32% 16/50 [00:03<00:09,  3.77it/s]\u001b[A\n"," 34% 17/50 [00:04<00:08,  3.76it/s]\u001b[A\n"," 36% 18/50 [00:04<00:08,  3.76it/s]\u001b[A\n"," 38% 19/50 [00:04<00:08,  3.78it/s]\u001b[A\n"," 40% 20/50 [00:05<00:07,  3.78it/s]\u001b[A\n"," 42% 21/50 [00:05<00:07,  3.78it/s]\u001b[A\n"," 44% 22/50 [00:05<00:07,  3.79it/s]\u001b[A\n"," 46% 23/50 [00:05<00:07,  3.79it/s]\u001b[A\n"," 48% 24/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 50% 25/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 52% 26/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 54% 27/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 56% 28/50 [00:07<00:05,  3.77it/s]\u001b[A\n"," 58% 29/50 [00:07<00:05,  3.77it/s]\u001b[A\n"," 60% 30/50 [00:07<00:05,  3.77it/s]\u001b[A\n"," 62% 31/50 [00:07<00:05,  3.76it/s]\u001b[A\n"," 64% 32/50 [00:08<00:04,  3.76it/s]\u001b[A\n"," 66% 33/50 [00:08<00:04,  3.76it/s]\u001b[A\n"," 68% 34/50 [00:08<00:04,  3.76it/s]\u001b[A\n"," 70% 35/50 [00:09<00:03,  3.76it/s]\u001b[A\n"," 72% 36/50 [00:09<00:03,  3.78it/s]\u001b[A\n"," 74% 37/50 [00:09<00:03,  3.77it/s]\u001b[A\n"," 76% 38/50 [00:09<00:03,  3.78it/s]\u001b[A\n"," 78% 39/50 [00:10<00:02,  3.77it/s]\u001b[A\n"," 80% 40/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 82% 41/50 [00:10<00:02,  3.78it/s]\u001b[A\n"," 84% 42/50 [00:10<00:02,  3.78it/s]\u001b[A\n"," 86% 43/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 88% 44/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 90% 45/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 92% 46/50 [00:11<00:01,  3.80it/s]\u001b[A\n"," 94% 47/50 [00:12<00:00,  3.79it/s]\u001b[A\n"," 96% 48/50 [00:12<00:00,  3.80it/s]\u001b[A\n"," 98% 49/50 [00:12<00:00,  3.79it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.48704269528388977, 'eval_accuracy': 0.8725, 'eval_precision': 0.8197424892703863, 'eval_recall': 0.955, 'eval_f1': 0.8822170900692841, 'eval_runtime': 13.2331, 'eval_samples_per_second': 30.227, 'eval_steps_per_second': 3.778, 'epoch': 1.0}\n"," 33% 200/600 [02:40<04:52,  1.37it/s]\n","100% 50/50 [00:12<00:00,  3.79it/s]\u001b[A\n","                                   \u001b[ASaving model checkpoint to output/checkpoint-200\n","Configuration saved in output/checkpoint-200/config.json\n","Model weights saved in output/checkpoint-200/pytorch_model.bin\n"," 67% 400/600 [05:12<02:27,  1.36it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: language, review_title, stars, product_category, product_id, review_body, reviewer_id, review_id. If language, review_title, stars, product_category, product_id, review_body, reviewer_id, review_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 8\n","\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:06,  7.39it/s]\u001b[A\n","  6% 3/50 [00:00<00:08,  5.23it/s]\u001b[A\n","  8% 4/50 [00:00<00:10,  4.55it/s]\u001b[A\n"," 10% 5/50 [00:01<00:10,  4.29it/s]\u001b[A\n"," 12% 6/50 [00:01<00:10,  4.07it/s]\u001b[A\n"," 14% 7/50 [00:01<00:10,  3.93it/s]\u001b[A\n"," 16% 8/50 [00:01<00:10,  3.89it/s]\u001b[A\n"," 18% 9/50 [00:02<00:10,  3.88it/s]\u001b[A\n"," 20% 10/50 [00:02<00:10,  3.83it/s]\u001b[A\n"," 22% 11/50 [00:02<00:10,  3.80it/s]\u001b[A\n"," 24% 12/50 [00:02<00:09,  3.80it/s]\u001b[A\n"," 26% 13/50 [00:03<00:09,  3.80it/s]\u001b[A\n"," 28% 14/50 [00:03<00:09,  3.76it/s]\u001b[A\n"," 30% 15/50 [00:03<00:09,  3.75it/s]\u001b[A\n"," 32% 16/50 [00:04<00:09,  3.76it/s]\u001b[A\n"," 34% 17/50 [00:04<00:08,  3.77it/s]\u001b[A\n"," 36% 18/50 [00:04<00:08,  3.75it/s]\u001b[A\n"," 38% 19/50 [00:04<00:08,  3.75it/s]\u001b[A\n"," 40% 20/50 [00:05<00:07,  3.76it/s]\u001b[A\n"," 42% 21/50 [00:05<00:07,  3.76it/s]\u001b[A\n"," 44% 22/50 [00:05<00:07,  3.74it/s]\u001b[A\n"," 46% 23/50 [00:05<00:07,  3.75it/s]\u001b[A\n"," 48% 24/50 [00:06<00:06,  3.76it/s]\u001b[A\n"," 50% 25/50 [00:06<00:06,  3.77it/s]\u001b[A\n"," 52% 26/50 [00:06<00:06,  3.77it/s]\u001b[A\n"," 54% 27/50 [00:06<00:06,  3.77it/s]\u001b[A\n"," 56% 28/50 [00:07<00:05,  3.76it/s]\u001b[A\n"," 58% 29/50 [00:07<00:05,  3.75it/s]\u001b[A\n"," 60% 30/50 [00:07<00:05,  3.74it/s]\u001b[A\n"," 62% 31/50 [00:07<00:05,  3.74it/s]\u001b[A\n"," 64% 32/50 [00:08<00:04,  3.75it/s]\u001b[A\n"," 66% 33/50 [00:08<00:04,  3.75it/s]\u001b[A\n"," 68% 34/50 [00:08<00:04,  3.75it/s]\u001b[A\n"," 70% 35/50 [00:09<00:03,  3.75it/s]\u001b[A\n"," 72% 36/50 [00:09<00:03,  3.75it/s]\u001b[A\n"," 74% 37/50 [00:09<00:03,  3.75it/s]\u001b[A\n"," 76% 38/50 [00:09<00:03,  3.73it/s]\u001b[A\n"," 78% 39/50 [00:10<00:02,  3.75it/s]\u001b[A\n"," 80% 40/50 [00:10<00:02,  3.76it/s]\u001b[A\n"," 82% 41/50 [00:10<00:02,  3.77it/s]\u001b[A\n"," 84% 42/50 [00:10<00:02,  3.77it/s]\u001b[A\n"," 86% 43/50 [00:11<00:01,  3.78it/s]\u001b[A\n"," 88% 44/50 [00:11<00:01,  3.78it/s]\u001b[A\n"," 90% 45/50 [00:11<00:01,  3.77it/s]\u001b[A\n"," 92% 46/50 [00:11<00:01,  3.78it/s]\u001b[A\n"," 94% 47/50 [00:12<00:00,  3.79it/s]\u001b[A\n"," 96% 48/50 [00:12<00:00,  3.78it/s]\u001b[A\n"," 98% 49/50 [00:12<00:00,  3.77it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.42364639043807983, 'eval_accuracy': 0.8825, 'eval_precision': 0.8695652173913043, 'eval_recall': 0.9, 'eval_f1': 0.8845208845208845, 'eval_runtime': 13.3046, 'eval_samples_per_second': 30.065, 'eval_steps_per_second': 3.758, 'epoch': 2.0}\n"," 67% 400/600 [05:26<02:27,  1.36it/s]\n","100% 50/50 [00:13<00:00,  3.77it/s]\u001b[A\n","                                   \u001b[ASaving model checkpoint to output/checkpoint-400\n","Configuration saved in output/checkpoint-400/config.json\n","Model weights saved in output/checkpoint-400/pytorch_model.bin\n","{'loss': 0.2819, 'learning_rate': 8.333333333333334e-06, 'epoch': 2.5}\n","100% 600/600 [07:57<00:00,  1.36it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: language, review_title, stars, product_category, product_id, review_body, reviewer_id, review_id. If language, review_title, stars, product_category, product_id, review_body, reviewer_id, review_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 8\n","\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:06,  7.49it/s]\u001b[A\n","  6% 3/50 [00:00<00:08,  5.29it/s]\u001b[A\n","  8% 4/50 [00:00<00:10,  4.57it/s]\u001b[A\n"," 10% 5/50 [00:01<00:10,  4.24it/s]\u001b[A\n"," 12% 6/50 [00:01<00:10,  4.06it/s]\u001b[A\n"," 14% 7/50 [00:01<00:10,  3.95it/s]\u001b[A\n"," 16% 8/50 [00:01<00:10,  3.88it/s]\u001b[A\n"," 18% 9/50 [00:02<00:10,  3.85it/s]\u001b[A\n"," 20% 10/50 [00:02<00:10,  3.80it/s]\u001b[A\n"," 22% 11/50 [00:02<00:10,  3.78it/s]\u001b[A\n"," 24% 12/50 [00:02<00:10,  3.79it/s]\u001b[A\n"," 26% 13/50 [00:03<00:09,  3.78it/s]\u001b[A\n"," 28% 14/50 [00:03<00:09,  3.77it/s]\u001b[A\n"," 30% 15/50 [00:03<00:09,  3.74it/s]\u001b[A\n"," 32% 16/50 [00:04<00:09,  3.74it/s]\u001b[A\n"," 34% 17/50 [00:04<00:08,  3.74it/s]\u001b[A\n"," 36% 18/50 [00:04<00:08,  3.74it/s]\u001b[A\n"," 38% 19/50 [00:04<00:08,  3.74it/s]\u001b[A\n"," 40% 20/50 [00:05<00:08,  3.74it/s]\u001b[A\n"," 42% 21/50 [00:05<00:07,  3.73it/s]\u001b[A\n"," 44% 22/50 [00:05<00:07,  3.73it/s]\u001b[A\n"," 46% 23/50 [00:05<00:07,  3.75it/s]\u001b[A\n"," 48% 24/50 [00:06<00:06,  3.76it/s]\u001b[A\n"," 50% 25/50 [00:06<00:06,  3.76it/s]\u001b[A\n"," 52% 26/50 [00:06<00:06,  3.74it/s]\u001b[A\n"," 54% 27/50 [00:06<00:06,  3.74it/s]\u001b[A\n"," 56% 28/50 [00:07<00:05,  3.73it/s]\u001b[A\n"," 58% 29/50 [00:07<00:05,  3.74it/s]\u001b[A\n"," 60% 30/50 [00:07<00:05,  3.74it/s]\u001b[A\n"," 62% 31/50 [00:08<00:05,  3.73it/s]\u001b[A\n"," 64% 32/50 [00:08<00:04,  3.72it/s]\u001b[A\n"," 66% 33/50 [00:08<00:04,  3.73it/s]\u001b[A\n"," 68% 34/50 [00:08<00:04,  3.76it/s]\u001b[A\n"," 70% 35/50 [00:09<00:03,  3.75it/s]\u001b[A\n"," 72% 36/50 [00:09<00:03,  3.74it/s]\u001b[A\n"," 74% 37/50 [00:09<00:03,  3.74it/s]\u001b[A\n"," 76% 38/50 [00:09<00:03,  3.74it/s]\u001b[A\n"," 78% 39/50 [00:10<00:02,  3.74it/s]\u001b[A\n"," 80% 40/50 [00:10<00:02,  3.74it/s]\u001b[A\n"," 82% 41/50 [00:10<00:02,  3.74it/s]\u001b[A\n"," 84% 42/50 [00:10<00:02,  3.75it/s]\u001b[A\n"," 86% 43/50 [00:11<00:01,  3.73it/s]\u001b[A\n"," 88% 44/50 [00:11<00:01,  3.74it/s]\u001b[A\n"," 90% 45/50 [00:11<00:01,  3.74it/s]\u001b[A\n"," 92% 46/50 [00:12<00:01,  3.73it/s]\u001b[A\n"," 94% 47/50 [00:12<00:00,  3.72it/s]\u001b[A\n"," 96% 48/50 [00:12<00:00,  3.73it/s]\u001b[A\n"," 98% 49/50 [00:12<00:00,  3.74it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.4720296561717987, 'eval_accuracy': 0.905, 'eval_precision': 0.905, 'eval_recall': 0.905, 'eval_f1': 0.905, 'eval_runtime': 13.3734, 'eval_samples_per_second': 29.91, 'eval_steps_per_second': 3.739, 'epoch': 3.0}\n","100% 600/600 [08:11<00:00,  1.36it/s]\n","100% 50/50 [00:13<00:00,  3.75it/s]\u001b[A\n","                                   \u001b[ASaving model checkpoint to output/checkpoint-600\n","Configuration saved in output/checkpoint-600/config.json\n","Model weights saved in output/checkpoint-600/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from output/checkpoint-400 (score: 0.42364639043807983).\n","{'train_runtime': 496.1487, 'train_samples_per_second': 9.675, 'train_steps_per_second': 1.209, 'train_loss': 0.25108978907267254, 'epoch': 3.0}\n","100% 600/600 [08:16<00:00,  1.21it/s]\n","Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","WARNING:datasets.builder:Found cached dataset amazon_reviews_multi (/root/.cache/huggingface/datasets/amazon_reviews_multi/ja/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/amazon_reviews_multi/ja/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-83f8d432a1e3b464.arrow\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/amazon_reviews_multi/ja/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-725ca478270fd589.arrow\n","100% 2/2 [00:00<00:00,  3.62ba/s]\n","100% 2/2 [00:01<00:00,  1.83ba/s]\n","100% 1/1 [00:00<00:00,  9.48ba/s]\n","100% 1/1 [00:00<00:00,  3.77ba/s]\n","Train data statistics: {'total': 1600, 'positive': 793, 'negative': 807}\n","Test data statistics: {'total': 400, 'positive': 207, 'negative': 193}\n","The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: review_title, product_id, reviewer_id, review_body, product_category, language, stars, review_id. If review_title, product_id, reviewer_id, review_body, product_category, language, stars, review_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1600\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 600\n","  Number of trainable parameters = 110618882\n"," 33% 200/600 [02:27<04:52,  1.37it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: review_title, product_id, reviewer_id, review_body, product_category, language, stars, review_id. If review_title, product_id, reviewer_id, review_body, product_category, language, stars, review_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 8\n","\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:06,  7.65it/s]\u001b[A\n","  6% 3/50 [00:00<00:08,  5.33it/s]\u001b[A\n","  8% 4/50 [00:00<00:09,  4.61it/s]\u001b[A\n"," 10% 5/50 [00:01<00:10,  4.31it/s]\u001b[A\n"," 12% 6/50 [00:01<00:10,  4.13it/s]\u001b[A\n"," 14% 7/50 [00:01<00:10,  3.99it/s]\u001b[A\n"," 16% 8/50 [00:01<00:10,  3.92it/s]\u001b[A\n"," 18% 9/50 [00:02<00:10,  3.88it/s]\u001b[A\n"," 20% 10/50 [00:02<00:10,  3.84it/s]\u001b[A\n"," 22% 11/50 [00:02<00:10,  3.82it/s]\u001b[A\n"," 24% 12/50 [00:02<00:09,  3.81it/s]\u001b[A\n"," 26% 13/50 [00:03<00:09,  3.81it/s]\u001b[A\n"," 28% 14/50 [00:03<00:09,  3.80it/s]\u001b[A\n"," 30% 15/50 [00:03<00:09,  3.80it/s]\u001b[A\n"," 32% 16/50 [00:03<00:08,  3.80it/s]\u001b[A\n"," 34% 17/50 [00:04<00:08,  3.80it/s]\u001b[A\n"," 36% 18/50 [00:04<00:08,  3.79it/s]\u001b[A\n"," 38% 19/50 [00:04<00:08,  3.80it/s]\u001b[A\n"," 40% 20/50 [00:05<00:07,  3.80it/s]\u001b[A\n"," 42% 21/50 [00:05<00:07,  3.79it/s]\u001b[A\n"," 44% 22/50 [00:05<00:07,  3.79it/s]\u001b[A\n"," 46% 23/50 [00:05<00:07,  3.80it/s]\u001b[A\n"," 48% 24/50 [00:06<00:06,  3.80it/s]\u001b[A\n"," 50% 25/50 [00:06<00:06,  3.78it/s]\u001b[A\n"," 52% 26/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 54% 27/50 [00:06<00:06,  3.80it/s]\u001b[A\n"," 56% 28/50 [00:07<00:05,  3.80it/s]\u001b[A\n"," 58% 29/50 [00:07<00:05,  3.78it/s]\u001b[A\n"," 60% 30/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 62% 31/50 [00:07<00:04,  3.80it/s]\u001b[A\n"," 64% 32/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 66% 33/50 [00:08<00:04,  3.78it/s]\u001b[A\n"," 68% 34/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 70% 35/50 [00:08<00:03,  3.79it/s]\u001b[A\n"," 72% 36/50 [00:09<00:03,  3.78it/s]\u001b[A\n"," 74% 37/50 [00:09<00:03,  3.78it/s]\u001b[A\n"," 76% 38/50 [00:09<00:03,  3.80it/s]\u001b[A\n"," 78% 39/50 [00:10<00:02,  3.80it/s]\u001b[A\n"," 80% 40/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 82% 41/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 84% 42/50 [00:10<00:02,  3.80it/s]\u001b[A\n"," 86% 43/50 [00:11<00:01,  3.81it/s]\u001b[A\n"," 88% 44/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 90% 45/50 [00:11<00:01,  3.78it/s]\u001b[A\n"," 92% 46/50 [00:11<00:01,  3.80it/s]\u001b[A\n"," 94% 47/50 [00:12<00:00,  3.80it/s]\u001b[A\n"," 96% 48/50 [00:12<00:00,  3.78it/s]\u001b[A\n"," 98% 49/50 [00:12<00:00,  3.79it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.28209811449050903, 'eval_accuracy': 0.905, 'eval_precision': 0.9121951219512195, 'eval_recall': 0.9033816425120773, 'eval_f1': 0.9077669902912623, 'eval_runtime': 13.1969, 'eval_samples_per_second': 30.31, 'eval_steps_per_second': 3.789, 'epoch': 1.0}\n"," 33% 200/600 [02:40<04:52,  1.37it/s]\n","100% 50/50 [00:12<00:00,  3.80it/s]\u001b[A\n","                                   \u001b[ASaving model checkpoint to output/checkpoint-200\n","Configuration saved in output/checkpoint-200/config.json\n","Model weights saved in output/checkpoint-200/pytorch_model.bin\n"," 67% 400/600 [05:12<02:26,  1.36it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: review_title, product_id, reviewer_id, review_body, product_category, language, stars, review_id. If review_title, product_id, reviewer_id, review_body, product_category, language, stars, review_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 8\n","\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:06,  7.50it/s]\u001b[A\n","  6% 3/50 [00:00<00:08,  5.25it/s]\u001b[A\n","  8% 4/50 [00:00<00:10,  4.58it/s]\u001b[A\n"," 10% 5/50 [00:01<00:10,  4.28it/s]\u001b[A\n"," 12% 6/50 [00:01<00:10,  4.08it/s]\u001b[A\n"," 14% 7/50 [00:01<00:10,  3.95it/s]\u001b[A\n"," 16% 8/50 [00:01<00:10,  3.91it/s]\u001b[A\n"," 18% 9/50 [00:02<00:10,  3.89it/s]\u001b[A\n"," 20% 10/50 [00:02<00:10,  3.82it/s]\u001b[A\n"," 22% 11/50 [00:02<00:10,  3.78it/s]\u001b[A\n"," 24% 12/50 [00:02<00:10,  3.79it/s]\u001b[A\n"," 26% 13/50 [00:03<00:09,  3.78it/s]\u001b[A\n"," 28% 14/50 [00:03<00:09,  3.77it/s]\u001b[A\n"," 30% 15/50 [00:03<00:09,  3.78it/s]\u001b[A\n"," 32% 16/50 [00:03<00:08,  3.79it/s]\u001b[A\n"," 34% 17/50 [00:04<00:08,  3.79it/s]\u001b[A\n"," 36% 18/50 [00:04<00:08,  3.77it/s]\u001b[A\n"," 38% 19/50 [00:04<00:08,  3.76it/s]\u001b[A\n"," 40% 20/50 [00:05<00:07,  3.78it/s]\u001b[A\n"," 42% 21/50 [00:05<00:07,  3.76it/s]\u001b[A\n"," 44% 22/50 [00:05<00:07,  3.76it/s]\u001b[A\n"," 46% 23/50 [00:05<00:07,  3.75it/s]\u001b[A\n"," 48% 24/50 [00:06<00:06,  3.75it/s]\u001b[A\n"," 50% 25/50 [00:06<00:06,  3.76it/s]\u001b[A\n"," 52% 26/50 [00:06<00:06,  3.76it/s]\u001b[A\n"," 54% 27/50 [00:06<00:06,  3.77it/s]\u001b[A\n"," 56% 28/50 [00:07<00:05,  3.77it/s]\u001b[A\n"," 58% 29/50 [00:07<00:05,  3.77it/s]\u001b[A\n"," 60% 30/50 [00:07<00:05,  3.78it/s]\u001b[A\n"," 62% 31/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 64% 32/50 [00:08<00:04,  3.78it/s]\u001b[A\n"," 66% 33/50 [00:08<00:04,  3.78it/s]\u001b[A\n"," 68% 34/50 [00:08<00:04,  3.78it/s]\u001b[A\n"," 70% 35/50 [00:09<00:03,  3.79it/s]\u001b[A\n"," 72% 36/50 [00:09<00:03,  3.78it/s]\u001b[A\n"," 74% 37/50 [00:09<00:03,  3.78it/s]\u001b[A\n"," 76% 38/50 [00:09<00:03,  3.78it/s]\u001b[A\n"," 78% 39/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 80% 40/50 [00:10<00:02,  3.78it/s]\u001b[A\n"," 82% 41/50 [00:10<00:02,  3.77it/s]\u001b[A\n"," 84% 42/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 86% 43/50 [00:11<00:01,  3.80it/s]\u001b[A\n"," 88% 44/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 90% 45/50 [00:11<00:01,  3.78it/s]\u001b[A\n"," 92% 46/50 [00:11<00:01,  3.80it/s]\u001b[A\n"," 94% 47/50 [00:12<00:00,  3.80it/s]\u001b[A\n"," 96% 48/50 [00:12<00:00,  3.78it/s]\u001b[A\n"," 98% 49/50 [00:12<00:00,  3.78it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.4173218607902527, 'eval_accuracy': 0.905, 'eval_precision': 0.9004739336492891, 'eval_recall': 0.9178743961352657, 'eval_f1': 0.9090909090909091, 'eval_runtime': 13.262, 'eval_samples_per_second': 30.161, 'eval_steps_per_second': 3.77, 'epoch': 2.0}\n"," 67% 400/600 [05:25<02:26,  1.36it/s]\n","100% 50/50 [00:12<00:00,  3.79it/s]\u001b[A\n","                                   \u001b[ASaving model checkpoint to output/checkpoint-400\n","Configuration saved in output/checkpoint-400/config.json\n","Model weights saved in output/checkpoint-400/pytorch_model.bin\n","{'loss': 0.2548, 'learning_rate': 8.333333333333334e-06, 'epoch': 2.5}\n","100% 600/600 [07:57<00:00,  1.36it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: review_title, product_id, reviewer_id, review_body, product_category, language, stars, review_id. If review_title, product_id, reviewer_id, review_body, product_category, language, stars, review_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 8\n","\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:06,  7.59it/s]\u001b[A\n","  6% 3/50 [00:00<00:08,  5.28it/s]\u001b[A\n","  8% 4/50 [00:00<00:09,  4.62it/s]\u001b[A\n"," 10% 5/50 [00:01<00:10,  4.30it/s]\u001b[A\n"," 12% 6/50 [00:01<00:10,  4.11it/s]\u001b[A\n"," 14% 7/50 [00:01<00:10,  3.97it/s]\u001b[A\n"," 16% 8/50 [00:01<00:10,  3.93it/s]\u001b[A\n"," 18% 9/50 [00:02<00:10,  3.89it/s]\u001b[A\n"," 20% 10/50 [00:02<00:10,  3.86it/s]\u001b[A\n"," 22% 11/50 [00:02<00:10,  3.83it/s]\u001b[A\n"," 24% 12/50 [00:02<00:09,  3.83it/s]\u001b[A\n"," 26% 13/50 [00:03<00:09,  3.82it/s]\u001b[A\n"," 28% 14/50 [00:03<00:09,  3.80it/s]\u001b[A\n"," 30% 15/50 [00:03<00:09,  3.80it/s]\u001b[A\n"," 32% 16/50 [00:03<00:08,  3.81it/s]\u001b[A\n"," 34% 17/50 [00:04<00:08,  3.80it/s]\u001b[A\n"," 36% 18/50 [00:04<00:08,  3.79it/s]\u001b[A\n"," 38% 19/50 [00:04<00:08,  3.79it/s]\u001b[A\n"," 40% 20/50 [00:05<00:07,  3.80it/s]\u001b[A\n"," 42% 21/50 [00:05<00:07,  3.80it/s]\u001b[A\n"," 44% 22/50 [00:05<00:07,  3.77it/s]\u001b[A\n"," 46% 23/50 [00:05<00:07,  3.77it/s]\u001b[A\n"," 48% 24/50 [00:06<00:06,  3.80it/s]\u001b[A\n"," 50% 25/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 52% 26/50 [00:06<00:06,  3.78it/s]\u001b[A\n"," 54% 27/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 56% 28/50 [00:07<00:05,  3.80it/s]\u001b[A\n"," 58% 29/50 [00:07<00:05,  3.80it/s]\u001b[A\n"," 60% 30/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 62% 31/50 [00:07<00:05,  3.80it/s]\u001b[A\n"," 64% 32/50 [00:08<00:04,  3.80it/s]\u001b[A\n"," 66% 33/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 68% 34/50 [00:08<00:04,  3.78it/s]\u001b[A\n"," 70% 35/50 [00:08<00:03,  3.79it/s]\u001b[A\n"," 72% 36/50 [00:09<00:03,  3.80it/s]\u001b[A\n"," 74% 37/50 [00:09<00:03,  3.79it/s]\u001b[A\n"," 76% 38/50 [00:09<00:03,  3.79it/s]\u001b[A\n"," 78% 39/50 [00:10<00:02,  3.80it/s]\u001b[A\n"," 80% 40/50 [00:10<00:02,  3.80it/s]\u001b[A\n"," 82% 41/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 84% 42/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 86% 43/50 [00:11<00:01,  3.80it/s]\u001b[A\n"," 88% 44/50 [00:11<00:01,  3.80it/s]\u001b[A\n"," 90% 45/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 92% 46/50 [00:11<00:01,  3.78it/s]\u001b[A\n"," 94% 47/50 [00:12<00:00,  3.79it/s]\u001b[A\n"," 96% 48/50 [00:12<00:00,  3.80it/s]\u001b[A\n"," 98% 49/50 [00:12<00:00,  3.79it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.46551352739334106, 'eval_accuracy': 0.915, 'eval_precision': 0.9178743961352657, 'eval_recall': 0.9178743961352657, 'eval_f1': 0.9178743961352658, 'eval_runtime': 13.1968, 'eval_samples_per_second': 30.31, 'eval_steps_per_second': 3.789, 'epoch': 3.0}\n","100% 600/600 [08:10<00:00,  1.36it/s]\n","100% 50/50 [00:12<00:00,  3.79it/s]\u001b[A\n","                                   \u001b[ASaving model checkpoint to output/checkpoint-600\n","Configuration saved in output/checkpoint-600/config.json\n","Model weights saved in output/checkpoint-600/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from output/checkpoint-200 (score: 0.28209811449050903).\n","{'train_runtime': 497.4881, 'train_samples_per_second': 9.648, 'train_steps_per_second': 1.206, 'train_loss': 0.225032745997111, 'epoch': 3.0}\n","100% 600/600 [08:17<00:00,  1.21it/s]\n","Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","WARNING:datasets.builder:Found cached dataset amazon_reviews_multi (/root/.cache/huggingface/datasets/amazon_reviews_multi/ja/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/amazon_reviews_multi/ja/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-83f8d432a1e3b464.arrow\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/amazon_reviews_multi/ja/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-725ca478270fd589.arrow\n","100% 2/2 [00:00<00:00,  3.51ba/s]\n","100% 2/2 [00:01<00:00,  1.81ba/s]\n","100% 1/1 [00:00<00:00, 10.14ba/s]\n","100% 1/1 [00:00<00:00,  3.79ba/s]\n","Train data statistics: {'total': 1600, 'positive': 788, 'negative': 812}\n","Test data statistics: {'total': 400, 'positive': 212, 'negative': 188}\n","The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: review_title, stars, language, product_id, review_body, reviewer_id, product_category, review_id. If review_title, stars, language, product_id, review_body, reviewer_id, product_category, review_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1600\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 600\n","  Number of trainable parameters = 110618882\n"," 33% 200/600 [02:27<04:53,  1.36it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: review_title, stars, language, product_id, review_body, reviewer_id, product_category, review_id. If review_title, stars, language, product_id, review_body, reviewer_id, product_category, review_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 8\n","\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:06,  7.57it/s]\u001b[A\n","  6% 3/50 [00:00<00:08,  5.28it/s]\u001b[A\n","  8% 4/50 [00:00<00:09,  4.62it/s]\u001b[A\n"," 10% 5/50 [00:01<00:10,  4.30it/s]\u001b[A\n"," 12% 6/50 [00:01<00:10,  4.09it/s]\u001b[A\n"," 14% 7/50 [00:01<00:10,  3.96it/s]\u001b[A\n"," 16% 8/50 [00:01<00:10,  3.95it/s]\u001b[A\n"," 18% 9/50 [00:02<00:10,  3.90it/s]\u001b[A\n"," 20% 10/50 [00:02<00:10,  3.85it/s]\u001b[A\n"," 22% 11/50 [00:02<00:10,  3.82it/s]\u001b[A\n"," 24% 12/50 [00:02<00:09,  3.84it/s]\u001b[A\n"," 26% 13/50 [00:03<00:09,  3.83it/s]\u001b[A\n"," 28% 14/50 [00:03<00:09,  3.79it/s]\u001b[A\n"," 30% 15/50 [00:03<00:09,  3.79it/s]\u001b[A\n"," 32% 16/50 [00:03<00:08,  3.81it/s]\u001b[A\n"," 34% 17/50 [00:04<00:08,  3.79it/s]\u001b[A\n"," 36% 18/50 [00:04<00:08,  3.76it/s]\u001b[A\n"," 38% 19/50 [00:04<00:08,  3.77it/s]\u001b[A\n"," 40% 20/50 [00:05<00:07,  3.76it/s]\u001b[A\n"," 42% 21/50 [00:05<00:07,  3.76it/s]\u001b[A\n"," 44% 22/50 [00:05<00:07,  3.77it/s]\u001b[A\n"," 46% 23/50 [00:05<00:07,  3.78it/s]\u001b[A\n"," 48% 24/50 [00:06<00:06,  3.78it/s]\u001b[A\n"," 50% 25/50 [00:06<00:06,  3.78it/s]\u001b[A\n"," 52% 26/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 54% 27/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 56% 28/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 58% 29/50 [00:07<00:05,  3.80it/s]\u001b[A\n"," 60% 30/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 62% 31/50 [00:07<00:05,  3.78it/s]\u001b[A\n"," 64% 32/50 [00:08<00:04,  3.80it/s]\u001b[A\n"," 66% 33/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 68% 34/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 70% 35/50 [00:08<00:03,  3.79it/s]\u001b[A\n"," 72% 36/50 [00:09<00:03,  3.79it/s]\u001b[A\n"," 74% 37/50 [00:09<00:03,  3.80it/s]\u001b[A\n"," 76% 38/50 [00:09<00:03,  3.79it/s]\u001b[A\n"," 78% 39/50 [00:10<00:02,  3.80it/s]\u001b[A\n"," 80% 40/50 [00:10<00:02,  3.80it/s]\u001b[A\n"," 82% 41/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 84% 42/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 86% 43/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 88% 44/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 90% 45/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 92% 46/50 [00:11<00:01,  3.78it/s]\u001b[A\n"," 94% 47/50 [00:12<00:00,  3.77it/s]\u001b[A\n"," 96% 48/50 [00:12<00:00,  3.78it/s]\u001b[A\n"," 98% 49/50 [00:12<00:00,  3.77it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.3453460931777954, 'eval_accuracy': 0.905, 'eval_precision': 0.9484536082474226, 'eval_recall': 0.8679245283018868, 'eval_f1': 0.9064039408866995, 'eval_runtime': 13.2191, 'eval_samples_per_second': 30.259, 'eval_steps_per_second': 3.782, 'epoch': 1.0}\n"," 33% 200/600 [02:40<04:53,  1.36it/s]\n","100% 50/50 [00:12<00:00,  3.78it/s]\u001b[A\n","                                   \u001b[ASaving model checkpoint to output/checkpoint-200\n","Configuration saved in output/checkpoint-200/config.json\n","Model weights saved in output/checkpoint-200/pytorch_model.bin\n"," 67% 400/600 [05:12<02:26,  1.36it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: review_title, stars, language, product_id, review_body, reviewer_id, product_category, review_id. If review_title, stars, language, product_id, review_body, reviewer_id, product_category, review_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 8\n","\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:06,  7.75it/s]\u001b[A\n","  6% 3/50 [00:00<00:08,  5.35it/s]\u001b[A\n","  8% 4/50 [00:00<00:10,  4.59it/s]\u001b[A\n"," 10% 5/50 [00:01<00:10,  4.27it/s]\u001b[A\n"," 12% 6/50 [00:01<00:10,  4.10it/s]\u001b[A\n"," 14% 7/50 [00:01<00:10,  3.97it/s]\u001b[A\n"," 16% 8/50 [00:01<00:10,  3.90it/s]\u001b[A\n"," 18% 9/50 [00:02<00:10,  3.86it/s]\u001b[A\n"," 20% 10/50 [00:02<00:10,  3.83it/s]\u001b[A\n"," 22% 11/50 [00:02<00:10,  3.79it/s]\u001b[A\n"," 24% 12/50 [00:02<00:10,  3.78it/s]\u001b[A\n"," 26% 13/50 [00:03<00:09,  3.78it/s]\u001b[A\n"," 28% 14/50 [00:03<00:09,  3.78it/s]\u001b[A\n"," 30% 15/50 [00:03<00:09,  3.76it/s]\u001b[A\n"," 32% 16/50 [00:03<00:09,  3.76it/s]\u001b[A\n"," 34% 17/50 [00:04<00:08,  3.75it/s]\u001b[A\n"," 36% 18/50 [00:04<00:08,  3.74it/s]\u001b[A\n"," 38% 19/50 [00:04<00:08,  3.73it/s]\u001b[A\n"," 40% 20/50 [00:05<00:08,  3.74it/s]\u001b[A\n"," 42% 21/50 [00:05<00:07,  3.75it/s]\u001b[A\n"," 44% 22/50 [00:05<00:07,  3.75it/s]\u001b[A\n"," 46% 23/50 [00:05<00:07,  3.75it/s]\u001b[A\n"," 48% 24/50 [00:06<00:06,  3.74it/s]\u001b[A\n"," 50% 25/50 [00:06<00:06,  3.75it/s]\u001b[A\n"," 52% 26/50 [00:06<00:06,  3.76it/s]\u001b[A\n"," 54% 27/50 [00:06<00:06,  3.76it/s]\u001b[A\n"," 56% 28/50 [00:07<00:05,  3.75it/s]\u001b[A\n"," 58% 29/50 [00:07<00:05,  3.75it/s]\u001b[A\n"," 60% 30/50 [00:07<00:05,  3.75it/s]\u001b[A\n"," 62% 31/50 [00:07<00:05,  3.74it/s]\u001b[A\n"," 64% 32/50 [00:08<00:04,  3.74it/s]\u001b[A\n"," 66% 33/50 [00:08<00:04,  3.75it/s]\u001b[A\n"," 68% 34/50 [00:08<00:04,  3.75it/s]\u001b[A\n"," 70% 35/50 [00:09<00:04,  3.74it/s]\u001b[A\n"," 72% 36/50 [00:09<00:03,  3.73it/s]\u001b[A\n"," 74% 37/50 [00:09<00:03,  3.74it/s]\u001b[A\n"," 76% 38/50 [00:09<00:03,  3.75it/s]\u001b[A\n"," 78% 39/50 [00:10<00:02,  3.75it/s]\u001b[A\n"," 80% 40/50 [00:10<00:02,  3.75it/s]\u001b[A\n"," 82% 41/50 [00:10<00:02,  3.74it/s]\u001b[A\n"," 84% 42/50 [00:10<00:02,  3.76it/s]\u001b[A\n"," 86% 43/50 [00:11<00:01,  3.75it/s]\u001b[A\n"," 88% 44/50 [00:11<00:01,  3.74it/s]\u001b[A\n"," 90% 45/50 [00:11<00:01,  3.75it/s]\u001b[A\n"," 92% 46/50 [00:12<00:01,  3.75it/s]\u001b[A\n"," 94% 47/50 [00:12<00:00,  3.76it/s]\u001b[A\n"," 96% 48/50 [00:12<00:00,  3.76it/s]\u001b[A\n"," 98% 49/50 [00:12<00:00,  3.75it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.36802008748054504, 'eval_accuracy': 0.9025, 'eval_precision': 0.9576719576719577, 'eval_recall': 0.8537735849056604, 'eval_f1': 0.9027431421446384, 'eval_runtime': 13.3382, 'eval_samples_per_second': 29.989, 'eval_steps_per_second': 3.749, 'epoch': 2.0}\n"," 67% 400/600 [05:25<02:26,  1.36it/s]\n","100% 50/50 [00:13<00:00,  3.75it/s]\u001b[A\n","                                   \u001b[ASaving model checkpoint to output/checkpoint-400\n","Configuration saved in output/checkpoint-400/config.json\n","Model weights saved in output/checkpoint-400/pytorch_model.bin\n","{'loss': 0.2808, 'learning_rate': 8.333333333333334e-06, 'epoch': 2.5}\n","100% 600/600 [07:57<00:00,  1.37it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: review_title, stars, language, product_id, review_body, reviewer_id, product_category, review_id. If review_title, stars, language, product_id, review_body, reviewer_id, product_category, review_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 8\n","\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:06,  7.44it/s]\u001b[A\n","  6% 3/50 [00:00<00:08,  5.29it/s]\u001b[A\n","  8% 4/50 [00:00<00:10,  4.60it/s]\u001b[A\n"," 10% 5/50 [00:01<00:10,  4.28it/s]\u001b[A\n"," 12% 6/50 [00:01<00:10,  4.08it/s]\u001b[A\n"," 14% 7/50 [00:01<00:10,  3.95it/s]\u001b[A\n"," 16% 8/50 [00:01<00:10,  3.91it/s]\u001b[A\n"," 18% 9/50 [00:02<00:10,  3.86it/s]\u001b[A\n"," 20% 10/50 [00:02<00:10,  3.83it/s]\u001b[A\n"," 22% 11/50 [00:02<00:10,  3.81it/s]\u001b[A\n"," 24% 12/50 [00:02<00:09,  3.82it/s]\u001b[A\n"," 26% 13/50 [00:03<00:09,  3.81it/s]\u001b[A\n"," 28% 14/50 [00:03<00:09,  3.80it/s]\u001b[A\n"," 30% 15/50 [00:03<00:09,  3.80it/s]\u001b[A\n"," 32% 16/50 [00:03<00:08,  3.81it/s]\u001b[A\n"," 34% 17/50 [00:04<00:08,  3.80it/s]\u001b[A\n"," 36% 18/50 [00:04<00:08,  3.79it/s]\u001b[A\n"," 38% 19/50 [00:04<00:08,  3.79it/s]\u001b[A\n"," 40% 20/50 [00:05<00:07,  3.80it/s]\u001b[A\n"," 42% 21/50 [00:05<00:07,  3.79it/s]\u001b[A\n"," 44% 22/50 [00:05<00:07,  3.79it/s]\u001b[A\n"," 46% 23/50 [00:05<00:07,  3.78it/s]\u001b[A\n"," 48% 24/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 50% 25/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 52% 26/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 54% 27/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 56% 28/50 [00:07<00:05,  3.80it/s]\u001b[A\n"," 58% 29/50 [00:07<00:05,  3.80it/s]\u001b[A\n"," 60% 30/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 62% 31/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 64% 32/50 [00:08<00:04,  3.80it/s]\u001b[A\n"," 66% 33/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 68% 34/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 70% 35/50 [00:08<00:03,  3.79it/s]\u001b[A\n"," 72% 36/50 [00:09<00:03,  3.79it/s]\u001b[A\n"," 74% 37/50 [00:09<00:03,  3.79it/s]\u001b[A\n"," 76% 38/50 [00:09<00:03,  3.80it/s]\u001b[A\n"," 78% 39/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 80% 40/50 [00:10<00:02,  3.80it/s]\u001b[A\n"," 82% 41/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 84% 42/50 [00:10<00:02,  3.80it/s]\u001b[A\n"," 86% 43/50 [00:11<00:01,  3.80it/s]\u001b[A\n"," 88% 44/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 90% 45/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 92% 46/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 94% 47/50 [00:12<00:00,  3.79it/s]\u001b[A\n"," 96% 48/50 [00:12<00:00,  3.80it/s]\u001b[A\n"," 98% 49/50 [00:12<00:00,  3.79it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.4306192100048065, 'eval_accuracy': 0.91, 'eval_precision': 0.94, 'eval_recall': 0.8867924528301887, 'eval_f1': 0.912621359223301, 'eval_runtime': 13.2105, 'eval_samples_per_second': 30.279, 'eval_steps_per_second': 3.785, 'epoch': 3.0}\n","100% 600/600 [08:10<00:00,  1.37it/s]\n","100% 50/50 [00:12<00:00,  3.80it/s]\u001b[A\n","                                   \u001b[ASaving model checkpoint to output/checkpoint-600\n","Configuration saved in output/checkpoint-600/config.json\n","Model weights saved in output/checkpoint-600/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from output/checkpoint-200 (score: 0.3453460931777954).\n","{'train_runtime': 497.3043, 'train_samples_per_second': 9.652, 'train_steps_per_second': 1.207, 'train_loss': 0.25184733549753824, 'epoch': 3.0}\n","100% 600/600 [08:17<00:00,  1.21it/s]\n","Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","WARNING:datasets.builder:Found cached dataset amazon_reviews_multi (/root/.cache/huggingface/datasets/amazon_reviews_multi/ja/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/amazon_reviews_multi/ja/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-83f8d432a1e3b464.arrow\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/amazon_reviews_multi/ja/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-725ca478270fd589.arrow\n","100% 2/2 [00:00<00:00,  3.64ba/s]\n","100% 2/2 [00:01<00:00,  1.86ba/s]\n","100% 1/1 [00:00<00:00, 10.59ba/s]\n","100% 1/1 [00:00<00:00,  3.69ba/s]\n","Train data statistics: {'total': 1600, 'positive': 797, 'negative': 803}\n","Test data statistics: {'total': 400, 'positive': 203, 'negative': 197}\n","The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: review_title, language, reviewer_id, product_category, review_id, stars, review_body, product_id. If review_title, language, reviewer_id, product_category, review_id, stars, review_body, product_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1600\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 600\n","  Number of trainable parameters = 110618882\n"," 33% 200/600 [02:27<04:53,  1.36it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: review_title, language, reviewer_id, product_category, review_id, stars, review_body, product_id. If review_title, language, reviewer_id, product_category, review_id, stars, review_body, product_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 8\n","\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:06,  7.49it/s]\u001b[A\n","  6% 3/50 [00:00<00:08,  5.27it/s]\u001b[A\n","  8% 4/50 [00:00<00:10,  4.58it/s]\u001b[A\n"," 10% 5/50 [00:01<00:10,  4.30it/s]\u001b[A\n"," 12% 6/50 [00:01<00:10,  4.09it/s]\u001b[A\n"," 14% 7/50 [00:01<00:10,  3.97it/s]\u001b[A\n"," 16% 8/50 [00:01<00:10,  3.90it/s]\u001b[A\n"," 18% 9/50 [00:02<00:10,  3.86it/s]\u001b[A\n"," 20% 10/50 [00:02<00:10,  3.82it/s]\u001b[A\n"," 22% 11/50 [00:02<00:10,  3.81it/s]\u001b[A\n"," 24% 12/50 [00:02<00:09,  3.82it/s]\u001b[A\n"," 26% 13/50 [00:03<00:09,  3.81it/s]\u001b[A\n"," 28% 14/50 [00:03<00:09,  3.80it/s]\u001b[A\n"," 30% 15/50 [00:03<00:09,  3.80it/s]\u001b[A\n"," 32% 16/50 [00:03<00:08,  3.80it/s]\u001b[A\n"," 34% 17/50 [00:04<00:08,  3.80it/s]\u001b[A\n"," 36% 18/50 [00:04<00:08,  3.79it/s]\u001b[A\n"," 38% 19/50 [00:04<00:08,  3.80it/s]\u001b[A\n"," 40% 20/50 [00:05<00:07,  3.80it/s]\u001b[A\n"," 42% 21/50 [00:05<00:07,  3.79it/s]\u001b[A\n"," 44% 22/50 [00:05<00:07,  3.79it/s]\u001b[A\n"," 46% 23/50 [00:05<00:07,  3.80it/s]\u001b[A\n"," 48% 24/50 [00:06<00:06,  3.80it/s]\u001b[A\n"," 50% 25/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 52% 26/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 54% 27/50 [00:06<00:06,  3.80it/s]\u001b[A\n"," 56% 28/50 [00:07<00:05,  3.80it/s]\u001b[A\n"," 58% 29/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 60% 30/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 62% 31/50 [00:07<00:05,  3.80it/s]\u001b[A\n"," 64% 32/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 66% 33/50 [00:08<00:04,  3.78it/s]\u001b[A\n"," 68% 34/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 70% 35/50 [00:08<00:03,  3.80it/s]\u001b[A\n"," 72% 36/50 [00:09<00:03,  3.80it/s]\u001b[A\n"," 74% 37/50 [00:09<00:03,  3.79it/s]\u001b[A\n"," 76% 38/50 [00:09<00:03,  3.80it/s]\u001b[A\n"," 78% 39/50 [00:10<00:02,  3.80it/s]\u001b[A\n"," 80% 40/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 82% 41/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 84% 42/50 [00:10<00:02,  3.80it/s]\u001b[A\n"," 86% 43/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 88% 44/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 90% 45/50 [00:11<00:01,  3.78it/s]\u001b[A\n"," 92% 46/50 [00:11<00:01,  3.80it/s]\u001b[A\n"," 94% 47/50 [00:12<00:00,  3.79it/s]\u001b[A\n"," 96% 48/50 [00:12<00:00,  3.80it/s]\u001b[A\n"," 98% 49/50 [00:12<00:00,  3.79it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.222849503159523, 'eval_accuracy': 0.915, 'eval_precision': 0.8967136150234741, 'eval_recall': 0.9408866995073891, 'eval_f1': 0.9182692307692307, 'eval_runtime': 13.2086, 'eval_samples_per_second': 30.283, 'eval_steps_per_second': 3.785, 'epoch': 1.0}\n"," 33% 200/600 [02:40<04:53,  1.36it/s]\n","100% 50/50 [00:12<00:00,  3.80it/s]\u001b[A\n","                                   \u001b[ASaving model checkpoint to output/checkpoint-200\n","Configuration saved in output/checkpoint-200/config.json\n","Model weights saved in output/checkpoint-200/pytorch_model.bin\n"," 67% 400/600 [05:12<02:26,  1.37it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: review_title, language, reviewer_id, product_category, review_id, stars, review_body, product_id. If review_title, language, reviewer_id, product_category, review_id, stars, review_body, product_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 8\n","\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:06,  7.51it/s]\u001b[A\n","  6% 3/50 [00:00<00:08,  5.27it/s]\u001b[A\n","  8% 4/50 [00:00<00:09,  4.62it/s]\u001b[A\n"," 10% 5/50 [00:01<00:10,  4.31it/s]\u001b[A\n"," 12% 6/50 [00:01<00:10,  4.10it/s]\u001b[A\n"," 14% 7/50 [00:01<00:10,  3.97it/s]\u001b[A\n"," 16% 8/50 [00:01<00:10,  3.94it/s]\u001b[A\n"," 18% 9/50 [00:02<00:10,  3.90it/s]\u001b[A\n"," 20% 10/50 [00:02<00:10,  3.84it/s]\u001b[A\n"," 22% 11/50 [00:02<00:10,  3.81it/s]\u001b[A\n"," 24% 12/50 [00:02<00:09,  3.83it/s]\u001b[A\n"," 26% 13/50 [00:03<00:09,  3.82it/s]\u001b[A\n"," 28% 14/50 [00:03<00:09,  3.80it/s]\u001b[A\n"," 30% 15/50 [00:03<00:09,  3.78it/s]\u001b[A\n"," 32% 16/50 [00:03<00:08,  3.80it/s]\u001b[A\n"," 34% 17/50 [00:04<00:08,  3.78it/s]\u001b[A\n"," 36% 18/50 [00:04<00:08,  3.79it/s]\u001b[A\n"," 38% 19/50 [00:04<00:08,  3.79it/s]\u001b[A\n"," 40% 20/50 [00:05<00:07,  3.81it/s]\u001b[A\n"," 42% 21/50 [00:05<00:07,  3.79it/s]\u001b[A\n"," 44% 22/50 [00:05<00:07,  3.79it/s]\u001b[A\n"," 46% 23/50 [00:05<00:07,  3.78it/s]\u001b[A\n"," 48% 24/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 50% 25/50 [00:06<00:06,  3.78it/s]\u001b[A\n"," 52% 26/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 54% 27/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 56% 28/50 [00:07<00:05,  3.80it/s]\u001b[A\n"," 58% 29/50 [00:07<00:05,  3.80it/s]\u001b[A\n"," 60% 30/50 [00:07<00:05,  3.80it/s]\u001b[A\n"," 62% 31/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 64% 32/50 [00:08<00:04,  3.80it/s]\u001b[A\n"," 66% 33/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 68% 34/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 70% 35/50 [00:08<00:03,  3.78it/s]\u001b[A\n"," 72% 36/50 [00:09<00:03,  3.79it/s]\u001b[A\n"," 74% 37/50 [00:09<00:03,  3.80it/s]\u001b[A\n"," 76% 38/50 [00:09<00:03,  3.80it/s]\u001b[A\n"," 78% 39/50 [00:10<00:02,  3.80it/s]\u001b[A\n"," 80% 40/50 [00:10<00:02,  3.81it/s]\u001b[A\n"," 82% 41/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 84% 42/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 86% 43/50 [00:11<00:01,  3.80it/s]\u001b[A\n"," 88% 44/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 90% 45/50 [00:11<00:01,  3.78it/s]\u001b[A\n"," 92% 46/50 [00:11<00:01,  3.76it/s]\u001b[A\n"," 94% 47/50 [00:12<00:00,  3.77it/s]\u001b[A\n"," 96% 48/50 [00:12<00:00,  3.77it/s]\u001b[A\n"," 98% 49/50 [00:12<00:00,  3.77it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.35779860615730286, 'eval_accuracy': 0.905, 'eval_precision': 0.914572864321608, 'eval_recall': 0.896551724137931, 'eval_f1': 0.9054726368159204, 'eval_runtime': 13.2108, 'eval_samples_per_second': 30.278, 'eval_steps_per_second': 3.785, 'epoch': 2.0}\n"," 67% 400/600 [05:26<02:26,  1.37it/s]\n","100% 50/50 [00:12<00:00,  3.78it/s]\u001b[A\n","                                   \u001b[ASaving model checkpoint to output/checkpoint-400\n","Configuration saved in output/checkpoint-400/config.json\n","Model weights saved in output/checkpoint-400/pytorch_model.bin\n","{'loss': 0.2826, 'learning_rate': 8.333333333333334e-06, 'epoch': 2.5}\n","100% 600/600 [07:57<00:00,  1.36it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: review_title, language, reviewer_id, product_category, review_id, stars, review_body, product_id. If review_title, language, reviewer_id, product_category, review_id, stars, review_body, product_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 8\n","\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:06,  7.49it/s]\u001b[A\n","  6% 3/50 [00:00<00:08,  5.31it/s]\u001b[A\n","  8% 4/50 [00:00<00:10,  4.59it/s]\u001b[A\n"," 10% 5/50 [00:01<00:10,  4.28it/s]\u001b[A\n"," 12% 6/50 [00:01<00:10,  4.08it/s]\u001b[A\n"," 14% 7/50 [00:01<00:10,  3.94it/s]\u001b[A\n"," 16% 8/50 [00:01<00:10,  3.89it/s]\u001b[A\n"," 18% 9/50 [00:02<00:10,  3.85it/s]\u001b[A\n"," 20% 10/50 [00:02<00:10,  3.82it/s]\u001b[A\n"," 22% 11/50 [00:02<00:10,  3.78it/s]\u001b[A\n"," 24% 12/50 [00:02<00:09,  3.80it/s]\u001b[A\n"," 26% 13/50 [00:03<00:09,  3.79it/s]\u001b[A\n"," 28% 14/50 [00:03<00:09,  3.74it/s]\u001b[A\n"," 30% 15/50 [00:03<00:09,  3.74it/s]\u001b[A\n"," 32% 16/50 [00:04<00:09,  3.76it/s]\u001b[A\n"," 34% 17/50 [00:04<00:08,  3.77it/s]\u001b[A\n"," 36% 18/50 [00:04<00:08,  3.76it/s]\u001b[A\n"," 38% 19/50 [00:04<00:08,  3.74it/s]\u001b[A\n"," 40% 20/50 [00:05<00:08,  3.75it/s]\u001b[A\n"," 42% 21/50 [00:05<00:07,  3.74it/s]\u001b[A\n"," 44% 22/50 [00:05<00:07,  3.74it/s]\u001b[A\n"," 46% 23/50 [00:05<00:07,  3.74it/s]\u001b[A\n"," 48% 24/50 [00:06<00:06,  3.77it/s]\u001b[A\n"," 50% 25/50 [00:06<00:06,  3.74it/s]\u001b[A\n"," 52% 26/50 [00:06<00:06,  3.74it/s]\u001b[A\n"," 54% 27/50 [00:06<00:06,  3.74it/s]\u001b[A\n"," 56% 28/50 [00:07<00:05,  3.76it/s]\u001b[A\n"," 58% 29/50 [00:07<00:05,  3.76it/s]\u001b[A\n"," 60% 30/50 [00:07<00:05,  3.77it/s]\u001b[A\n"," 62% 31/50 [00:07<00:05,  3.77it/s]\u001b[A\n"," 64% 32/50 [00:08<00:04,  3.76it/s]\u001b[A\n"," 66% 33/50 [00:08<00:04,  3.75it/s]\u001b[A\n"," 68% 34/50 [00:08<00:04,  3.73it/s]\u001b[A\n"," 70% 35/50 [00:09<00:04,  3.74it/s]\u001b[A\n"," 72% 36/50 [00:09<00:03,  3.75it/s]\u001b[A\n"," 74% 37/50 [00:09<00:03,  3.75it/s]\u001b[A\n"," 76% 38/50 [00:09<00:03,  3.74it/s]\u001b[A\n"," 78% 39/50 [00:10<00:02,  3.73it/s]\u001b[A\n"," 80% 40/50 [00:10<00:02,  3.74it/s]\u001b[A\n"," 82% 41/50 [00:10<00:02,  3.75it/s]\u001b[A\n"," 84% 42/50 [00:10<00:02,  3.74it/s]\u001b[A\n"," 86% 43/50 [00:11<00:01,  3.74it/s]\u001b[A\n"," 88% 44/50 [00:11<00:01,  3.74it/s]\u001b[A\n"," 90% 45/50 [00:11<00:01,  3.73it/s]\u001b[A\n"," 92% 46/50 [00:12<00:01,  3.74it/s]\u001b[A\n"," 94% 47/50 [00:12<00:00,  3.74it/s]\u001b[A\n"," 96% 48/50 [00:12<00:00,  3.74it/s]\u001b[A\n"," 98% 49/50 [00:12<00:00,  3.73it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.43398016691207886, 'eval_accuracy': 0.91, 'eval_precision': 0.9282051282051282, 'eval_recall': 0.8916256157635468, 'eval_f1': 0.9095477386934674, 'eval_runtime': 13.3516, 'eval_samples_per_second': 29.959, 'eval_steps_per_second': 3.745, 'epoch': 3.0}\n","100% 600/600 [08:10<00:00,  1.36it/s]\n","100% 50/50 [00:13<00:00,  3.73it/s]\u001b[A\n","                                   \u001b[ASaving model checkpoint to output/checkpoint-600\n","Configuration saved in output/checkpoint-600/config.json\n","Model weights saved in output/checkpoint-600/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from output/checkpoint-200 (score: 0.222849503159523).\n","{'train_runtime': 498.1299, 'train_samples_per_second': 9.636, 'train_steps_per_second': 1.205, 'train_loss': 0.2553206300735474, 'epoch': 3.0}\n","100% 600/600 [08:18<00:00,  1.20it/s]\n","Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","WARNING:datasets.builder:Found cached dataset amazon_reviews_multi (/root/.cache/huggingface/datasets/amazon_reviews_multi/ja/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/amazon_reviews_multi/ja/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-83f8d432a1e3b464.arrow\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/amazon_reviews_multi/ja/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-725ca478270fd589.arrow\n","100% 2/2 [00:00<00:00,  3.51ba/s]\n","100% 2/2 [00:01<00:00,  1.74ba/s]\n","100% 1/1 [00:00<00:00,  9.87ba/s]\n","100% 1/1 [00:00<00:00,  3.44ba/s]\n","Train data statistics: {'total': 1600, 'positive': 801, 'negative': 799}\n","Test data statistics: {'total': 400, 'positive': 199, 'negative': 201}\n","The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: language, review_title, stars, product_category, product_id, review_id, review_body, reviewer_id. If language, review_title, stars, product_category, product_id, review_id, review_body, reviewer_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1600\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 600\n","  Number of trainable parameters = 110618882\n"," 33% 200/600 [02:27<04:53,  1.36it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: language, review_title, stars, product_category, product_id, review_id, review_body, reviewer_id. If language, review_title, stars, product_category, product_id, review_id, review_body, reviewer_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 8\n","\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:06,  7.43it/s]\u001b[A\n","  6% 3/50 [00:00<00:08,  5.31it/s]\u001b[A\n","  8% 4/50 [00:00<00:09,  4.62it/s]\u001b[A\n"," 10% 5/50 [00:01<00:10,  4.32it/s]\u001b[A\n"," 12% 6/50 [00:01<00:10,  4.10it/s]\u001b[A\n"," 14% 7/50 [00:01<00:10,  3.97it/s]\u001b[A\n"," 16% 8/50 [00:01<00:10,  3.91it/s]\u001b[A\n"," 18% 9/50 [00:02<00:10,  3.89it/s]\u001b[A\n"," 20% 10/50 [00:02<00:10,  3.83it/s]\u001b[A\n"," 22% 11/50 [00:02<00:10,  3.79it/s]\u001b[A\n"," 24% 12/50 [00:02<00:10,  3.79it/s]\u001b[A\n"," 26% 13/50 [00:03<00:09,  3.78it/s]\u001b[A\n"," 28% 14/50 [00:03<00:09,  3.77it/s]\u001b[A\n"," 30% 15/50 [00:03<00:09,  3.78it/s]\u001b[A\n"," 32% 16/50 [00:03<00:08,  3.79it/s]\u001b[A\n"," 34% 17/50 [00:04<00:08,  3.79it/s]\u001b[A\n"," 36% 18/50 [00:04<00:08,  3.79it/s]\u001b[A\n"," 38% 19/50 [00:04<00:08,  3.79it/s]\u001b[A\n"," 40% 20/50 [00:05<00:07,  3.80it/s]\u001b[A\n"," 42% 21/50 [00:05<00:07,  3.79it/s]\u001b[A\n"," 44% 22/50 [00:05<00:07,  3.79it/s]\u001b[A\n"," 46% 23/50 [00:05<00:07,  3.79it/s]\u001b[A\n"," 48% 24/50 [00:06<00:06,  3.80it/s]\u001b[A\n"," 50% 25/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 52% 26/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 54% 27/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 56% 28/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 58% 29/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 60% 30/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 62% 31/50 [00:07<00:05,  3.80it/s]\u001b[A\n"," 64% 32/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 66% 33/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 68% 34/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 70% 35/50 [00:08<00:03,  3.79it/s]\u001b[A\n"," 72% 36/50 [00:09<00:03,  3.79it/s]\u001b[A\n"," 74% 37/50 [00:09<00:03,  3.80it/s]\u001b[A\n"," 76% 38/50 [00:09<00:03,  3.80it/s]\u001b[A\n"," 78% 39/50 [00:10<00:02,  3.80it/s]\u001b[A\n"," 80% 40/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 82% 41/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 84% 42/50 [00:10<00:02,  3.80it/s]\u001b[A\n"," 86% 43/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 88% 44/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 90% 45/50 [00:11<00:01,  3.80it/s]\u001b[A\n"," 92% 46/50 [00:11<00:01,  3.80it/s]\u001b[A\n"," 94% 47/50 [00:12<00:00,  3.79it/s]\u001b[A\n"," 96% 48/50 [00:12<00:00,  3.80it/s]\u001b[A\n"," 98% 49/50 [00:12<00:00,  3.80it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.2969985008239746, 'eval_accuracy': 0.905, 'eval_precision': 0.8779342723004695, 'eval_recall': 0.9396984924623115, 'eval_f1': 0.9077669902912621, 'eval_runtime': 13.2082, 'eval_samples_per_second': 30.284, 'eval_steps_per_second': 3.786, 'epoch': 1.0}\n"," 33% 200/600 [02:40<04:53,  1.36it/s]\n","100% 50/50 [00:12<00:00,  3.80it/s]\u001b[A\n","                                   \u001b[ASaving model checkpoint to output/checkpoint-200\n","Configuration saved in output/checkpoint-200/config.json\n","Model weights saved in output/checkpoint-200/pytorch_model.bin\n"," 67% 400/600 [05:12<02:26,  1.37it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: language, review_title, stars, product_category, product_id, review_id, review_body, reviewer_id. If language, review_title, stars, product_category, product_id, review_id, review_body, reviewer_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 8\n","\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:06,  7.44it/s]\u001b[A\n","  6% 3/50 [00:00<00:08,  5.28it/s]\u001b[A\n","  8% 4/50 [00:00<00:10,  4.58it/s]\u001b[A\n"," 10% 5/50 [00:01<00:10,  4.31it/s]\u001b[A\n"," 12% 6/50 [00:01<00:10,  4.10it/s]\u001b[A\n"," 14% 7/50 [00:01<00:10,  3.95it/s]\u001b[A\n"," 16% 8/50 [00:01<00:10,  3.88it/s]\u001b[A\n"," 18% 9/50 [00:02<00:10,  3.85it/s]\u001b[A\n"," 20% 10/50 [00:02<00:10,  3.82it/s]\u001b[A\n"," 22% 11/50 [00:02<00:10,  3.79it/s]\u001b[A\n"," 24% 12/50 [00:02<00:10,  3.78it/s]\u001b[A\n"," 26% 13/50 [00:03<00:09,  3.78it/s]\u001b[A\n"," 28% 14/50 [00:03<00:09,  3.75it/s]\u001b[A\n"," 30% 15/50 [00:03<00:09,  3.75it/s]\u001b[A\n"," 32% 16/50 [00:04<00:09,  3.76it/s]\u001b[A\n"," 34% 17/50 [00:04<00:08,  3.77it/s]\u001b[A\n"," 36% 18/50 [00:04<00:08,  3.76it/s]\u001b[A\n"," 38% 19/50 [00:04<00:08,  3.76it/s]\u001b[A\n"," 40% 20/50 [00:05<00:07,  3.78it/s]\u001b[A\n"," 42% 21/50 [00:05<00:07,  3.78it/s]\u001b[A\n"," 44% 22/50 [00:05<00:07,  3.77it/s]\u001b[A\n"," 46% 23/50 [00:05<00:07,  3.76it/s]\u001b[A\n"," 48% 24/50 [00:06<00:06,  3.77it/s]\u001b[A\n"," 50% 25/50 [00:06<00:06,  3.76it/s]\u001b[A\n"," 52% 26/50 [00:06<00:06,  3.74it/s]\u001b[A\n"," 54% 27/50 [00:06<00:06,  3.75it/s]\u001b[A\n"," 56% 28/50 [00:07<00:05,  3.76it/s]\u001b[A\n"," 58% 29/50 [00:07<00:05,  3.76it/s]\u001b[A\n"," 60% 30/50 [00:07<00:05,  3.75it/s]\u001b[A\n"," 62% 31/50 [00:07<00:05,  3.75it/s]\u001b[A\n"," 64% 32/50 [00:08<00:04,  3.75it/s]\u001b[A\n"," 66% 33/50 [00:08<00:04,  3.74it/s]\u001b[A\n"," 68% 34/50 [00:08<00:04,  3.75it/s]\u001b[A\n"," 70% 35/50 [00:09<00:04,  3.75it/s]\u001b[A\n"," 72% 36/50 [00:09<00:03,  3.75it/s]\u001b[A\n"," 74% 37/50 [00:09<00:03,  3.75it/s]\u001b[A\n"," 76% 38/50 [00:09<00:03,  3.75it/s]\u001b[A\n"," 78% 39/50 [00:10<00:02,  3.75it/s]\u001b[A\n"," 80% 40/50 [00:10<00:02,  3.75it/s]\u001b[A\n"," 82% 41/50 [00:10<00:02,  3.75it/s]\u001b[A\n"," 84% 42/50 [00:10<00:02,  3.75it/s]\u001b[A\n"," 86% 43/50 [00:11<00:01,  3.76it/s]\u001b[A\n"," 88% 44/50 [00:11<00:01,  3.76it/s]\u001b[A\n"," 90% 45/50 [00:11<00:01,  3.77it/s]\u001b[A\n"," 92% 46/50 [00:11<00:01,  3.78it/s]\u001b[A\n"," 94% 47/50 [00:12<00:00,  3.77it/s]\u001b[A\n"," 96% 48/50 [00:12<00:00,  3.76it/s]\u001b[A\n"," 98% 49/50 [00:12<00:00,  3.76it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.2759391665458679, 'eval_accuracy': 0.9225, 'eval_precision': 0.9468085106382979, 'eval_recall': 0.8944723618090452, 'eval_f1': 0.9198966408268734, 'eval_runtime': 13.3207, 'eval_samples_per_second': 30.028, 'eval_steps_per_second': 3.754, 'epoch': 2.0}\n"," 67% 400/600 [05:25<02:26,  1.37it/s]\n","100% 50/50 [00:13<00:00,  3.75it/s]\u001b[A\n","                                   \u001b[ASaving model checkpoint to output/checkpoint-400\n","Configuration saved in output/checkpoint-400/config.json\n","Model weights saved in output/checkpoint-400/pytorch_model.bin\n","{'loss': 0.3072, 'learning_rate': 8.333333333333334e-06, 'epoch': 2.5}\n","100% 600/600 [07:57<00:00,  1.36it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: language, review_title, stars, product_category, product_id, review_id, review_body, reviewer_id. If language, review_title, stars, product_category, product_id, review_id, review_body, reviewer_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 8\n","\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:06,  7.39it/s]\u001b[A\n","  6% 3/50 [00:00<00:08,  5.24it/s]\u001b[A\n","  8% 4/50 [00:00<00:10,  4.55it/s]\u001b[A\n"," 10% 5/50 [00:01<00:10,  4.27it/s]\u001b[A\n"," 12% 6/50 [00:01<00:10,  4.05it/s]\u001b[A\n"," 14% 7/50 [00:01<00:10,  3.93it/s]\u001b[A\n"," 16% 8/50 [00:01<00:10,  3.90it/s]\u001b[A\n"," 18% 9/50 [00:02<00:10,  3.87it/s]\u001b[A\n"," 20% 10/50 [00:02<00:10,  3.82it/s]\u001b[A\n"," 22% 11/50 [00:02<00:10,  3.78it/s]\u001b[A\n"," 24% 12/50 [00:02<00:10,  3.76it/s]\u001b[A\n"," 26% 13/50 [00:03<00:09,  3.75it/s]\u001b[A\n"," 28% 14/50 [00:03<00:09,  3.75it/s]\u001b[A\n"," 30% 15/50 [00:03<00:09,  3.73it/s]\u001b[A\n"," 32% 16/50 [00:04<00:09,  3.73it/s]\u001b[A\n"," 34% 17/50 [00:04<00:08,  3.74it/s]\u001b[A\n"," 36% 18/50 [00:04<00:08,  3.75it/s]\u001b[A\n"," 38% 19/50 [00:04<00:08,  3.76it/s]\u001b[A\n"," 40% 20/50 [00:05<00:07,  3.75it/s]\u001b[A\n"," 42% 21/50 [00:05<00:07,  3.73it/s]\u001b[A\n"," 44% 22/50 [00:05<00:07,  3.73it/s]\u001b[A\n"," 46% 23/50 [00:05<00:07,  3.74it/s]\u001b[A\n"," 48% 24/50 [00:06<00:06,  3.73it/s]\u001b[A\n"," 50% 25/50 [00:06<00:06,  3.75it/s]\u001b[A\n"," 52% 26/50 [00:06<00:06,  3.73it/s]\u001b[A\n"," 54% 27/50 [00:06<00:06,  3.73it/s]\u001b[A\n"," 56% 28/50 [00:07<00:05,  3.75it/s]\u001b[A\n"," 58% 29/50 [00:07<00:05,  3.75it/s]\u001b[A\n"," 60% 30/50 [00:07<00:05,  3.73it/s]\u001b[A\n"," 62% 31/50 [00:08<00:05,  3.72it/s]\u001b[A\n"," 64% 32/50 [00:08<00:04,  3.74it/s]\u001b[A\n"," 66% 33/50 [00:08<00:04,  3.74it/s]\u001b[A\n"," 68% 34/50 [00:08<00:04,  3.75it/s]\u001b[A\n"," 70% 35/50 [00:09<00:04,  3.74it/s]\u001b[A\n"," 72% 36/50 [00:09<00:03,  3.75it/s]\u001b[A\n"," 74% 37/50 [00:09<00:03,  3.74it/s]\u001b[A\n"," 76% 38/50 [00:09<00:03,  3.73it/s]\u001b[A\n"," 78% 39/50 [00:10<00:02,  3.73it/s]\u001b[A\n"," 80% 40/50 [00:10<00:02,  3.74it/s]\u001b[A\n"," 82% 41/50 [00:10<00:02,  3.73it/s]\u001b[A\n"," 84% 42/50 [00:10<00:02,  3.73it/s]\u001b[A\n"," 86% 43/50 [00:11<00:01,  3.76it/s]\u001b[A\n"," 88% 44/50 [00:11<00:01,  3.75it/s]\u001b[A\n"," 90% 45/50 [00:11<00:01,  3.74it/s]\u001b[A\n"," 92% 46/50 [00:12<00:01,  3.74it/s]\u001b[A\n"," 94% 47/50 [00:12<00:00,  3.74it/s]\u001b[A\n"," 96% 48/50 [00:12<00:00,  3.73it/s]\u001b[A\n"," 98% 49/50 [00:12<00:00,  3.73it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.31720563769340515, 'eval_accuracy': 0.9375, 'eval_precision': 0.9484536082474226, 'eval_recall': 0.9246231155778895, 'eval_f1': 0.9363867684478372, 'eval_runtime': 13.3782, 'eval_samples_per_second': 29.899, 'eval_steps_per_second': 3.737, 'epoch': 3.0}\n","100% 600/600 [08:10<00:00,  1.36it/s]\n","100% 50/50 [00:13<00:00,  3.73it/s]\u001b[A\n","                                   \u001b[ASaving model checkpoint to output/checkpoint-600\n","Configuration saved in output/checkpoint-600/config.json\n","Model weights saved in output/checkpoint-600/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from output/checkpoint-400 (score: 0.2759391665458679).\n","{'train_runtime': 495.972, 'train_samples_per_second': 9.678, 'train_steps_per_second': 1.21, 'train_loss': 0.26940353711446124, 'epoch': 3.0}\n","100% 600/600 [08:15<00:00,  1.21it/s]\n","Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","WARNING:datasets.builder:Found cached dataset amazon_reviews_multi (/root/.cache/huggingface/datasets/amazon_reviews_multi/ja/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/amazon_reviews_multi/ja/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-83f8d432a1e3b464.arrow\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/amazon_reviews_multi/ja/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-725ca478270fd589.arrow\n","100% 2/2 [00:00<00:00,  3.56ba/s]\n","100% 2/2 [00:01<00:00,  1.77ba/s]\n","100% 1/1 [00:00<00:00, 10.16ba/s]\n","100% 1/1 [00:00<00:00,  3.59ba/s]\n","Train data statistics: {'total': 1600, 'positive': 803, 'negative': 797}\n","Test data statistics: {'total': 400, 'positive': 197, 'negative': 203}\n","The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: product_category, review_body, reviewer_id, product_id, review_id, review_title, language, stars. If product_category, review_body, reviewer_id, product_id, review_id, review_title, language, stars are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1600\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 600\n","  Number of trainable parameters = 110618882\n"," 33% 200/600 [02:27<04:53,  1.36it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: product_category, review_body, reviewer_id, product_id, review_id, review_title, language, stars. If product_category, review_body, reviewer_id, product_id, review_id, review_title, language, stars are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 8\n","\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:06,  7.39it/s]\u001b[A\n","  6% 3/50 [00:00<00:08,  5.25it/s]\u001b[A\n","  8% 4/50 [00:00<00:10,  4.55it/s]\u001b[A\n"," 10% 5/50 [00:01<00:10,  4.24it/s]\u001b[A\n"," 12% 6/50 [00:01<00:10,  4.04it/s]\u001b[A\n"," 14% 7/50 [00:01<00:10,  3.93it/s]\u001b[A\n"," 16% 8/50 [00:01<00:10,  3.91it/s]\u001b[A\n"," 18% 9/50 [00:02<00:10,  3.85it/s]\u001b[A\n"," 20% 10/50 [00:02<00:10,  3.81it/s]\u001b[A\n"," 22% 11/50 [00:02<00:10,  3.78it/s]\u001b[A\n"," 24% 12/50 [00:02<00:10,  3.79it/s]\u001b[A\n"," 26% 13/50 [00:03<00:09,  3.78it/s]\u001b[A\n"," 28% 14/50 [00:03<00:09,  3.78it/s]\u001b[A\n"," 30% 15/50 [00:03<00:09,  3.77it/s]\u001b[A\n"," 32% 16/50 [00:04<00:09,  3.77it/s]\u001b[A\n"," 34% 17/50 [00:04<00:08,  3.75it/s]\u001b[A\n"," 36% 18/50 [00:04<00:08,  3.73it/s]\u001b[A\n"," 38% 19/50 [00:04<00:08,  3.76it/s]\u001b[A\n"," 40% 20/50 [00:05<00:07,  3.76it/s]\u001b[A\n"," 42% 21/50 [00:05<00:07,  3.78it/s]\u001b[A\n"," 44% 22/50 [00:05<00:07,  3.75it/s]\u001b[A\n"," 46% 23/50 [00:05<00:07,  3.77it/s]\u001b[A\n"," 48% 24/50 [00:06<00:06,  3.76it/s]\u001b[A\n"," 50% 25/50 [00:06<00:06,  3.74it/s]\u001b[A\n"," 52% 26/50 [00:06<00:06,  3.76it/s]\u001b[A\n"," 54% 27/50 [00:06<00:06,  3.77it/s]\u001b[A\n"," 56% 28/50 [00:07<00:05,  3.77it/s]\u001b[A\n"," 58% 29/50 [00:07<00:05,  3.77it/s]\u001b[A\n"," 60% 30/50 [00:07<00:05,  3.76it/s]\u001b[A\n"," 62% 31/50 [00:07<00:05,  3.76it/s]\u001b[A\n"," 64% 32/50 [00:08<00:04,  3.74it/s]\u001b[A\n"," 66% 33/50 [00:08<00:04,  3.73it/s]\u001b[A\n"," 68% 34/50 [00:08<00:04,  3.76it/s]\u001b[A\n"," 70% 35/50 [00:09<00:03,  3.76it/s]\u001b[A\n"," 72% 36/50 [00:09<00:03,  3.76it/s]\u001b[A\n"," 74% 37/50 [00:09<00:03,  3.76it/s]\u001b[A\n"," 76% 38/50 [00:09<00:03,  3.76it/s]\u001b[A\n"," 78% 39/50 [00:10<00:02,  3.75it/s]\u001b[A\n"," 80% 40/50 [00:10<00:02,  3.73it/s]\u001b[A\n"," 82% 41/50 [00:10<00:02,  3.75it/s]\u001b[A\n"," 84% 42/50 [00:10<00:02,  3.77it/s]\u001b[A\n"," 86% 43/50 [00:11<00:01,  3.76it/s]\u001b[A\n"," 88% 44/50 [00:11<00:01,  3.75it/s]\u001b[A\n"," 90% 45/50 [00:11<00:01,  3.75it/s]\u001b[A\n"," 92% 46/50 [00:11<00:01,  3.77it/s]\u001b[A\n"," 94% 47/50 [00:12<00:00,  3.75it/s]\u001b[A\n"," 96% 48/50 [00:12<00:00,  3.74it/s]\u001b[A\n"," 98% 49/50 [00:12<00:00,  3.75it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.29661452770233154, 'eval_accuracy': 0.9075, 'eval_precision': 0.8921568627450981, 'eval_recall': 0.9238578680203046, 'eval_f1': 0.9077306733167083, 'eval_runtime': 13.3271, 'eval_samples_per_second': 30.014, 'eval_steps_per_second': 3.752, 'epoch': 1.0}\n"," 33% 200/600 [02:40<04:53,  1.36it/s]\n","100% 50/50 [00:13<00:00,  3.76it/s]\u001b[A\n","                                   \u001b[ASaving model checkpoint to output/checkpoint-200\n","Configuration saved in output/checkpoint-200/config.json\n","Model weights saved in output/checkpoint-200/pytorch_model.bin\n"," 67% 400/600 [05:12<02:25,  1.37it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: product_category, review_body, reviewer_id, product_id, review_id, review_title, language, stars. If product_category, review_body, reviewer_id, product_id, review_id, review_title, language, stars are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 8\n","\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:06,  7.71it/s]\u001b[A\n","  6% 3/50 [00:00<00:08,  5.35it/s]\u001b[A\n","  8% 4/50 [00:00<00:09,  4.61it/s]\u001b[A\n"," 10% 5/50 [00:01<00:10,  4.27it/s]\u001b[A\n"," 12% 6/50 [00:01<00:10,  4.09it/s]\u001b[A\n"," 14% 7/50 [00:01<00:10,  3.98it/s]\u001b[A\n"," 16% 8/50 [00:01<00:10,  3.93it/s]\u001b[A\n"," 18% 9/50 [00:02<00:10,  3.89it/s]\u001b[A\n"," 20% 10/50 [00:02<00:10,  3.85it/s]\u001b[A\n"," 22% 11/50 [00:02<00:10,  3.82it/s]\u001b[A\n"," 24% 12/50 [00:02<00:09,  3.82it/s]\u001b[A\n"," 26% 13/50 [00:03<00:09,  3.81it/s]\u001b[A\n"," 28% 14/50 [00:03<00:09,  3.80it/s]\u001b[A\n"," 30% 15/50 [00:03<00:09,  3.79it/s]\u001b[A\n"," 32% 16/50 [00:03<00:08,  3.80it/s]\u001b[A\n"," 34% 17/50 [00:04<00:08,  3.80it/s]\u001b[A\n"," 36% 18/50 [00:04<00:08,  3.79it/s]\u001b[A\n"," 38% 19/50 [00:04<00:08,  3.78it/s]\u001b[A\n"," 40% 20/50 [00:05<00:07,  3.80it/s]\u001b[A\n"," 42% 21/50 [00:05<00:07,  3.80it/s]\u001b[A\n"," 44% 22/50 [00:05<00:07,  3.78it/s]\u001b[A\n"," 46% 23/50 [00:05<00:07,  3.79it/s]\u001b[A\n"," 48% 24/50 [00:06<00:06,  3.80it/s]\u001b[A\n"," 50% 25/50 [00:06<00:06,  3.80it/s]\u001b[A\n"," 52% 26/50 [00:06<00:06,  3.78it/s]\u001b[A\n"," 54% 27/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 56% 28/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 58% 29/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 60% 30/50 [00:07<00:05,  3.78it/s]\u001b[A\n"," 62% 31/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 64% 32/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 66% 33/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 68% 34/50 [00:08<00:04,  3.78it/s]\u001b[A\n"," 70% 35/50 [00:08<00:03,  3.79it/s]\u001b[A\n"," 72% 36/50 [00:09<00:03,  3.79it/s]\u001b[A\n"," 74% 37/50 [00:09<00:03,  3.78it/s]\u001b[A\n"," 76% 38/50 [00:09<00:03,  3.78it/s]\u001b[A\n"," 78% 39/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 80% 40/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 82% 41/50 [00:10<00:02,  3.78it/s]\u001b[A\n"," 84% 42/50 [00:10<00:02,  3.76it/s]\u001b[A\n"," 86% 43/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 88% 44/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 90% 45/50 [00:11<00:01,  3.78it/s]\u001b[A\n"," 92% 46/50 [00:11<00:01,  3.78it/s]\u001b[A\n"," 94% 47/50 [00:12<00:00,  3.79it/s]\u001b[A\n"," 96% 48/50 [00:12<00:00,  3.79it/s]\u001b[A\n"," 98% 49/50 [00:12<00:00,  3.79it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.4725401997566223, 'eval_accuracy': 0.9125, 'eval_precision': 0.8932038834951457, 'eval_recall': 0.934010152284264, 'eval_f1': 0.913151364764268, 'eval_runtime': 13.2131, 'eval_samples_per_second': 30.273, 'eval_steps_per_second': 3.784, 'epoch': 2.0}\n"," 67% 400/600 [05:25<02:25,  1.37it/s]\n","100% 50/50 [00:12<00:00,  3.79it/s]\u001b[A\n","                                   \u001b[ASaving model checkpoint to output/checkpoint-400\n","Configuration saved in output/checkpoint-400/config.json\n","Model weights saved in output/checkpoint-400/pytorch_model.bin\n","{'loss': 0.2692, 'learning_rate': 8.333333333333334e-06, 'epoch': 2.5}\n","100% 600/600 [07:57<00:00,  1.37it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: product_category, review_body, reviewer_id, product_id, review_id, review_title, language, stars. If product_category, review_body, reviewer_id, product_id, review_id, review_title, language, stars are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 8\n","\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:06,  7.45it/s]\u001b[A\n","  6% 3/50 [00:00<00:08,  5.28it/s]\u001b[A\n","  8% 4/50 [00:00<00:10,  4.59it/s]\u001b[A\n"," 10% 5/50 [00:01<00:10,  4.30it/s]\u001b[A\n"," 12% 6/50 [00:01<00:10,  4.08it/s]\u001b[A\n"," 14% 7/50 [00:01<00:10,  3.94it/s]\u001b[A\n"," 16% 8/50 [00:01<00:10,  3.88it/s]\u001b[A\n"," 18% 9/50 [00:02<00:10,  3.85it/s]\u001b[A\n"," 20% 10/50 [00:02<00:10,  3.81it/s]\u001b[A\n"," 22% 11/50 [00:02<00:10,  3.77it/s]\u001b[A\n"," 24% 12/50 [00:02<00:10,  3.79it/s]\u001b[A\n"," 26% 13/50 [00:03<00:09,  3.78it/s]\u001b[A\n"," 28% 14/50 [00:03<00:09,  3.75it/s]\u001b[A\n"," 30% 15/50 [00:03<00:09,  3.76it/s]\u001b[A\n"," 32% 16/50 [00:04<00:09,  3.77it/s]\u001b[A\n"," 34% 17/50 [00:04<00:08,  3.78it/s]\u001b[A\n"," 36% 18/50 [00:04<00:08,  3.78it/s]\u001b[A\n"," 38% 19/50 [00:04<00:08,  3.78it/s]\u001b[A\n"," 40% 20/50 [00:05<00:07,  3.78it/s]\u001b[A\n"," 42% 21/50 [00:05<00:07,  3.79it/s]\u001b[A\n"," 44% 22/50 [00:05<00:07,  3.78it/s]\u001b[A\n"," 46% 23/50 [00:05<00:07,  3.77it/s]\u001b[A\n"," 48% 24/50 [00:06<00:06,  3.77it/s]\u001b[A\n"," 50% 25/50 [00:06<00:06,  3.77it/s]\u001b[A\n"," 52% 26/50 [00:06<00:06,  3.75it/s]\u001b[A\n"," 54% 27/50 [00:06<00:06,  3.75it/s]\u001b[A\n"," 56% 28/50 [00:07<00:05,  3.76it/s]\u001b[A\n"," 58% 29/50 [00:07<00:05,  3.76it/s]\u001b[A\n"," 60% 30/50 [00:07<00:05,  3.76it/s]\u001b[A\n"," 62% 31/50 [00:07<00:05,  3.74it/s]\u001b[A\n"," 64% 32/50 [00:08<00:04,  3.77it/s]\u001b[A\n"," 66% 33/50 [00:08<00:04,  3.75it/s]\u001b[A\n"," 68% 34/50 [00:08<00:04,  3.73it/s]\u001b[A\n"," 70% 35/50 [00:09<00:04,  3.75it/s]\u001b[A\n"," 72% 36/50 [00:09<00:03,  3.76it/s]\u001b[A\n"," 74% 37/50 [00:09<00:03,  3.77it/s]\u001b[A\n"," 76% 38/50 [00:09<00:03,  3.76it/s]\u001b[A\n"," 78% 39/50 [00:10<00:02,  3.78it/s]\u001b[A\n"," 80% 40/50 [00:10<00:02,  3.78it/s]\u001b[A\n"," 82% 41/50 [00:10<00:02,  3.77it/s]\u001b[A\n"," 84% 42/50 [00:10<00:02,  3.77it/s]\u001b[A\n"," 86% 43/50 [00:11<00:01,  3.78it/s]\u001b[A\n"," 88% 44/50 [00:11<00:01,  3.77it/s]\u001b[A\n"," 90% 45/50 [00:11<00:01,  3.75it/s]\u001b[A\n"," 92% 46/50 [00:11<00:01,  3.74it/s]\u001b[A\n"," 94% 47/50 [00:12<00:00,  3.76it/s]\u001b[A\n"," 96% 48/50 [00:12<00:00,  3.76it/s]\u001b[A\n"," 98% 49/50 [00:12<00:00,  3.76it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.4985423982143402, 'eval_accuracy': 0.91, 'eval_precision': 0.9086294416243654, 'eval_recall': 0.9086294416243654, 'eval_f1': 0.9086294416243654, 'eval_runtime': 13.3026, 'eval_samples_per_second': 30.069, 'eval_steps_per_second': 3.759, 'epoch': 3.0}\n","100% 600/600 [08:10<00:00,  1.37it/s]\n","100% 50/50 [00:13<00:00,  3.76it/s]\u001b[A\n","                                   \u001b[ASaving model checkpoint to output/checkpoint-600\n","Configuration saved in output/checkpoint-600/config.json\n","Model weights saved in output/checkpoint-600/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from output/checkpoint-200 (score: 0.29661452770233154).\n","{'train_runtime': 497.8174, 'train_samples_per_second': 9.642, 'train_steps_per_second': 1.205, 'train_loss': 0.2404062525431315, 'epoch': 3.0}\n","100% 600/600 [08:17<00:00,  1.21it/s]\n","Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","WARNING:datasets.builder:Found cached dataset amazon_reviews_multi (/root/.cache/huggingface/datasets/amazon_reviews_multi/ja/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/amazon_reviews_multi/ja/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-83f8d432a1e3b464.arrow\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/amazon_reviews_multi/ja/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-725ca478270fd589.arrow\n","100% 2/2 [00:00<00:00,  3.44ba/s]\n","100% 2/2 [00:01<00:00,  1.85ba/s]\n","100% 1/1 [00:00<00:00, 10.49ba/s]\n","100% 1/1 [00:00<00:00,  3.72ba/s]\n","Train data statistics: {'total': 1600, 'positive': 812, 'negative': 788}\n","Test data statistics: {'total': 400, 'positive': 188, 'negative': 212}\n","The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: language, product_category, review_body, review_title, product_id, reviewer_id, stars, review_id. If language, product_category, review_body, review_title, product_id, reviewer_id, stars, review_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1600\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 600\n","  Number of trainable parameters = 110618882\n"," 33% 200/600 [02:27<04:52,  1.37it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: language, product_category, review_body, review_title, product_id, reviewer_id, stars, review_id. If language, product_category, review_body, review_title, product_id, reviewer_id, stars, review_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 8\n","\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:06,  7.50it/s]\u001b[A\n","  6% 3/50 [00:00<00:08,  5.30it/s]\u001b[A\n","  8% 4/50 [00:00<00:09,  4.63it/s]\u001b[A\n"," 10% 5/50 [00:01<00:10,  4.31it/s]\u001b[A\n"," 12% 6/50 [00:01<00:10,  4.10it/s]\u001b[A\n"," 14% 7/50 [00:01<00:10,  3.98it/s]\u001b[A\n"," 16% 8/50 [00:01<00:10,  3.93it/s]\u001b[A\n"," 18% 9/50 [00:02<00:10,  3.91it/s]\u001b[A\n"," 20% 10/50 [00:02<00:10,  3.85it/s]\u001b[A\n"," 22% 11/50 [00:02<00:10,  3.84it/s]\u001b[A\n"," 24% 12/50 [00:02<00:09,  3.83it/s]\u001b[A\n"," 26% 13/50 [00:03<00:09,  3.82it/s]\u001b[A\n"," 28% 14/50 [00:03<00:09,  3.81it/s]\u001b[A\n"," 30% 15/50 [00:03<00:09,  3.81it/s]\u001b[A\n"," 32% 16/50 [00:03<00:08,  3.81it/s]\u001b[A\n"," 34% 17/50 [00:04<00:08,  3.80it/s]\u001b[A\n"," 36% 18/50 [00:04<00:08,  3.79it/s]\u001b[A\n"," 38% 19/50 [00:04<00:08,  3.79it/s]\u001b[A\n"," 40% 20/50 [00:05<00:07,  3.80it/s]\u001b[A\n"," 42% 21/50 [00:05<00:07,  3.79it/s]\u001b[A\n"," 44% 22/50 [00:05<00:07,  3.78it/s]\u001b[A\n"," 46% 23/50 [00:05<00:07,  3.79it/s]\u001b[A\n"," 48% 24/50 [00:06<00:06,  3.80it/s]\u001b[A\n"," 50% 25/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 52% 26/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 54% 27/50 [00:06<00:06,  3.80it/s]\u001b[A\n"," 56% 28/50 [00:07<00:05,  3.80it/s]\u001b[A\n"," 58% 29/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 60% 30/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 62% 31/50 [00:07<00:04,  3.80it/s]\u001b[A\n"," 64% 32/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 66% 33/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 68% 34/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 70% 35/50 [00:08<00:03,  3.80it/s]\u001b[A\n"," 72% 36/50 [00:09<00:03,  3.79it/s]\u001b[A\n"," 74% 37/50 [00:09<00:03,  3.79it/s]\u001b[A\n"," 76% 38/50 [00:09<00:03,  3.80it/s]\u001b[A\n"," 78% 39/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 80% 40/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 82% 41/50 [00:10<00:02,  3.78it/s]\u001b[A\n"," 84% 42/50 [00:10<00:02,  3.80it/s]\u001b[A\n"," 86% 43/50 [00:11<00:01,  3.80it/s]\u001b[A\n"," 88% 44/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 90% 45/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 92% 46/50 [00:11<00:01,  3.81it/s]\u001b[A\n"," 94% 47/50 [00:12<00:00,  3.79it/s]\u001b[A\n"," 96% 48/50 [00:12<00:00,  3.79it/s]\u001b[A\n"," 98% 49/50 [00:12<00:00,  3.79it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.2385733723640442, 'eval_accuracy': 0.9275, 'eval_precision': 0.8840579710144928, 'eval_recall': 0.973404255319149, 'eval_f1': 0.9265822784810127, 'eval_runtime': 13.1901, 'eval_samples_per_second': 30.326, 'eval_steps_per_second': 3.791, 'epoch': 1.0}\n"," 33% 200/600 [02:40<04:52,  1.37it/s]\n","100% 50/50 [00:12<00:00,  3.80it/s]\u001b[A\n","                                   \u001b[ASaving model checkpoint to output/checkpoint-200\n","Configuration saved in output/checkpoint-200/config.json\n","Model weights saved in output/checkpoint-200/pytorch_model.bin\n"," 67% 400/600 [05:12<02:26,  1.37it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: language, product_category, review_body, review_title, product_id, reviewer_id, stars, review_id. If language, product_category, review_body, review_title, product_id, reviewer_id, stars, review_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 8\n","\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:06,  7.49it/s]\u001b[A\n","  6% 3/50 [00:00<00:08,  5.30it/s]\u001b[A\n","  8% 4/50 [00:00<00:09,  4.62it/s]\u001b[A\n"," 10% 5/50 [00:01<00:10,  4.32it/s]\u001b[A\n"," 12% 6/50 [00:01<00:10,  4.11it/s]\u001b[A\n"," 14% 7/50 [00:01<00:10,  3.98it/s]\u001b[A\n"," 16% 8/50 [00:01<00:10,  3.94it/s]\u001b[A\n"," 18% 9/50 [00:02<00:10,  3.90it/s]\u001b[A\n"," 20% 10/50 [00:02<00:10,  3.86it/s]\u001b[A\n"," 22% 11/50 [00:02<00:10,  3.83it/s]\u001b[A\n"," 24% 12/50 [00:02<00:09,  3.83it/s]\u001b[A\n"," 26% 13/50 [00:03<00:09,  3.81it/s]\u001b[A\n"," 28% 14/50 [00:03<00:09,  3.80it/s]\u001b[A\n"," 30% 15/50 [00:03<00:09,  3.79it/s]\u001b[A\n"," 32% 16/50 [00:03<00:08,  3.81it/s]\u001b[A\n"," 34% 17/50 [00:04<00:08,  3.80it/s]\u001b[A\n"," 36% 18/50 [00:04<00:08,  3.79it/s]\u001b[A\n"," 38% 19/50 [00:04<00:08,  3.78it/s]\u001b[A\n"," 40% 20/50 [00:05<00:07,  3.80it/s]\u001b[A\n"," 42% 21/50 [00:05<00:07,  3.79it/s]\u001b[A\n"," 44% 22/50 [00:05<00:07,  3.80it/s]\u001b[A\n"," 46% 23/50 [00:05<00:07,  3.79it/s]\u001b[A\n"," 48% 24/50 [00:06<00:06,  3.80it/s]\u001b[A\n"," 50% 25/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 52% 26/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 54% 27/50 [00:06<00:06,  3.79it/s]\u001b[A\n"," 56% 28/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 58% 29/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 60% 30/50 [00:07<00:05,  3.78it/s]\u001b[A\n"," 62% 31/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 64% 32/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 66% 33/50 [00:08<00:04,  3.78it/s]\u001b[A\n"," 68% 34/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 70% 35/50 [00:08<00:03,  3.80it/s]\u001b[A\n"," 72% 36/50 [00:09<00:03,  3.79it/s]\u001b[A\n"," 74% 37/50 [00:09<00:03,  3.79it/s]\u001b[A\n"," 76% 38/50 [00:09<00:03,  3.79it/s]\u001b[A\n"," 78% 39/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 80% 40/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 82% 41/50 [00:10<00:02,  3.78it/s]\u001b[A\n"," 84% 42/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 86% 43/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 88% 44/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 90% 45/50 [00:11<00:01,  3.77it/s]\u001b[A\n"," 92% 46/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 94% 47/50 [00:12<00:00,  3.80it/s]\u001b[A\n"," 96% 48/50 [00:12<00:00,  3.79it/s]\u001b[A\n"," 98% 49/50 [00:12<00:00,  3.77it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.2919439375400543, 'eval_accuracy': 0.9225, 'eval_precision': 0.8905472636815921, 'eval_recall': 0.9521276595744681, 'eval_f1': 0.9203084832904884, 'eval_runtime': 13.2004, 'eval_samples_per_second': 30.302, 'eval_steps_per_second': 3.788, 'epoch': 2.0}\n"," 67% 400/600 [05:25<02:26,  1.37it/s]\n","100% 50/50 [00:12<00:00,  3.79it/s]\u001b[A\n","                                   \u001b[ASaving model checkpoint to output/checkpoint-400\n","Configuration saved in output/checkpoint-400/config.json\n","Model weights saved in output/checkpoint-400/pytorch_model.bin\n","{'loss': 0.2931, 'learning_rate': 8.333333333333334e-06, 'epoch': 2.5}\n","100% 600/600 [07:57<00:00,  1.37it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: language, product_category, review_body, review_title, product_id, reviewer_id, stars, review_id. If language, product_category, review_body, review_title, product_id, reviewer_id, stars, review_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 8\n","\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:06,  7.48it/s]\u001b[A\n","  6% 3/50 [00:00<00:08,  5.33it/s]\u001b[A\n","  8% 4/50 [00:00<00:09,  4.64it/s]\u001b[A\n"," 10% 5/50 [00:01<00:10,  4.31it/s]\u001b[A\n"," 12% 6/50 [00:01<00:10,  4.10it/s]\u001b[A\n"," 14% 7/50 [00:01<00:10,  3.98it/s]\u001b[A\n"," 16% 8/50 [00:01<00:10,  3.93it/s]\u001b[A\n"," 18% 9/50 [00:02<00:10,  3.89it/s]\u001b[A\n"," 20% 10/50 [00:02<00:10,  3.85it/s]\u001b[A\n"," 22% 11/50 [00:02<00:10,  3.83it/s]\u001b[A\n"," 24% 12/50 [00:02<00:09,  3.82it/s]\u001b[A\n"," 26% 13/50 [00:03<00:09,  3.81it/s]\u001b[A\n"," 28% 14/50 [00:03<00:09,  3.79it/s]\u001b[A\n"," 30% 15/50 [00:03<00:09,  3.78it/s]\u001b[A\n"," 32% 16/50 [00:03<00:08,  3.79it/s]\u001b[A\n"," 34% 17/50 [00:04<00:08,  3.78it/s]\u001b[A\n"," 36% 18/50 [00:04<00:08,  3.77it/s]\u001b[A\n"," 38% 19/50 [00:04<00:08,  3.79it/s]\u001b[A\n"," 40% 20/50 [00:05<00:07,  3.80it/s]\u001b[A\n"," 42% 21/50 [00:05<00:07,  3.78it/s]\u001b[A\n"," 44% 22/50 [00:05<00:07,  3.78it/s]\u001b[A\n"," 46% 23/50 [00:05<00:07,  3.77it/s]\u001b[A\n"," 48% 24/50 [00:06<00:06,  3.77it/s]\u001b[A\n"," 50% 25/50 [00:06<00:06,  3.76it/s]\u001b[A\n"," 52% 26/50 [00:06<00:06,  3.78it/s]\u001b[A\n"," 54% 27/50 [00:06<00:06,  3.78it/s]\u001b[A\n"," 56% 28/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 58% 29/50 [00:07<00:05,  3.78it/s]\u001b[A\n"," 60% 30/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 62% 31/50 [00:07<00:05,  3.79it/s]\u001b[A\n"," 64% 32/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 66% 33/50 [00:08<00:04,  3.78it/s]\u001b[A\n"," 68% 34/50 [00:08<00:04,  3.79it/s]\u001b[A\n"," 70% 35/50 [00:08<00:03,  3.79it/s]\u001b[A\n"," 72% 36/50 [00:09<00:03,  3.79it/s]\u001b[A\n"," 74% 37/50 [00:09<00:03,  3.77it/s]\u001b[A\n"," 76% 38/50 [00:09<00:03,  3.78it/s]\u001b[A\n"," 78% 39/50 [00:10<00:02,  3.79it/s]\u001b[A\n"," 80% 40/50 [00:10<00:02,  3.77it/s]\u001b[A\n"," 82% 41/50 [00:10<00:02,  3.77it/s]\u001b[A\n"," 84% 42/50 [00:10<00:02,  3.78it/s]\u001b[A\n"," 86% 43/50 [00:11<00:01,  3.78it/s]\u001b[A\n"," 88% 44/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 90% 45/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 92% 46/50 [00:11<00:01,  3.79it/s]\u001b[A\n"," 94% 47/50 [00:12<00:00,  3.79it/s]\u001b[A\n"," 96% 48/50 [00:12<00:00,  3.79it/s]\u001b[A\n"," 98% 49/50 [00:12<00:00,  3.79it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 0.35887211561203003, 'eval_accuracy': 0.935, 'eval_precision': 0.9263157894736842, 'eval_recall': 0.9361702127659575, 'eval_f1': 0.9312169312169313, 'eval_runtime': 13.2256, 'eval_samples_per_second': 30.244, 'eval_steps_per_second': 3.781, 'epoch': 3.0}\n","100% 600/600 [08:10<00:00,  1.37it/s]\n","100% 50/50 [00:12<00:00,  3.79it/s]\u001b[A\n","                                   \u001b[ASaving model checkpoint to output/checkpoint-600\n","Configuration saved in output/checkpoint-600/config.json\n","Model weights saved in output/checkpoint-600/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from output/checkpoint-200 (score: 0.2385733723640442).\n","{'train_runtime': 497.6624, 'train_samples_per_second': 9.645, 'train_steps_per_second': 1.206, 'train_loss': 0.26169623851776125, 'epoch': 3.0}\n","100% 600/600 [08:17<00:00,  1.21it/s]\n","8min 35s ± 956 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"]}],"source":["%%timeit\n","!python -m scripts.nlp.finetune"]}],"metadata":{"accelerator":"GPU","colab":{"name":"finetune_classification.ipynb","provenance":[{"file_id":"https://github.com/icoxfog417/notebook-bench/blob/main/notebooks/nlp.ipynb","timestamp":1669882322232}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}